{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f275652-29b3-43ea-b1d8-bf995345c0e4",
   "metadata": {},
   "source": [
    "1) **Generation Configuratinon:** Connecting to the Model and setting up Model parameters\n",
    "2) **Llama index History component** -> to mantain history of chat/conversation\n",
    "3) **Token count (ip and op)**\n",
    "4) **Google Embeddings model (other than word2vec model)**\n",
    "5) **Safety setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272c22de-2787-4237-a11c-9858a4cb11ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai #For accessing Gemini API or google genai model's\n",
    "import pathlib\n",
    "import textwrap        #for text refining  or display output in precise manner             \n",
    "from IPython.display import display #for text refining  \n",
    "from IPython.display import Markdown #for text refining "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd036d2-8cfa-4543-82c2-755dae562a0b",
   "metadata": {},
   "source": [
    "## Setting GEMINI_API_KEY in system environmental variable and Accessing To connect with Google's GenAI model's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b7251f-b028-4a81-8fda-46bd8e47b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "google_gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636552e1-8375-4ed7-b35f-c18acc585fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key = google_gemini_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdcdf5c-9e81-47d9-a28d-e72295c3d5d7",
   "metadata": {},
   "source": [
    "## Response formatting technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c0e2a4-3b48-4cf0-8cf9-4d97b5e08765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#windows + semicolon to open emoji and special symbol keypad\n",
    "def to_markdown(text):\n",
    "    text = text.replace(\"•\",\"  *\")\n",
    "    return Markdown(textwrap.indent(text,'> ', predicate = lambda _:True))\n",
    "\n",
    "#Bcz Gemini returns response containing bullet points,,so to convert it to star,,we defined this func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e75e08-5f64-4322-87af-8e2c1ac10aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> This is a   * sample text with bullet points."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_text = \"This is a • sample text with bullet points.\"\n",
    "result = to_markdown(input_text)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba9ba2-8dbb-4569-9fba-5454e5228de0",
   "metadata": {},
   "source": [
    "## 1) Generation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "889324fe-3735-41ac-8bd7-a0b902ba3333",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af042f1d-aece-4e88-b1c3-0c1f12445671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cac8f03-42ae-46fa-ae2b-d527e93f69da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>base_model_id</th>\n",
       "      <th>version</th>\n",
       "      <th>display_name</th>\n",
       "      <th>description</th>\n",
       "      <th>input_token_limit</th>\n",
       "      <th>output_token_limit</th>\n",
       "      <th>supported_generation_methods</th>\n",
       "      <th>temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>models/gemini-1.0-pro-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro Latest</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>models/gemini-1.0-pro</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>models/gemini-pro</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>models/gemini-1.0-pro-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro 001 (Tuning)</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens, createTunedModel]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>models/gemini-1.0-pro-vision-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro Vision</td>\n",
       "      <td>The best image understanding model to handle a...</td>\n",
       "      <td>12288</td>\n",
       "      <td>4096</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>models/gemini-pro-vision</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro Vision</td>\n",
       "      <td>The best image understanding model to handle a...</td>\n",
       "      <td>12288</td>\n",
       "      <td>4096</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>models/gemini-1.5-pro-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Pro Latest</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>2097152</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>models/gemini-1.5-pro-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Pro 001</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>2097152</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens, createCachedCon...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>models/gemini-1.5-pro</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Pro</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>2097152</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>models/gemini-1.5-flash-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Flash Latest</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>models/gemini-1.5-flash-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Flash 001</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens, createCachedCon...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>models/gemini-1.5-flash</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Flash</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name base_model_id version  \\\n",
       "0          models/gemini-1.0-pro-latest                   001   \n",
       "1                 models/gemini-1.0-pro                   001   \n",
       "2                     models/gemini-pro                   001   \n",
       "3             models/gemini-1.0-pro-001                   001   \n",
       "4   models/gemini-1.0-pro-vision-latest                   001   \n",
       "5              models/gemini-pro-vision                   001   \n",
       "6          models/gemini-1.5-pro-latest                   001   \n",
       "7             models/gemini-1.5-pro-001                   001   \n",
       "8                 models/gemini-1.5-pro                   001   \n",
       "9        models/gemini-1.5-flash-latest                   001   \n",
       "10          models/gemini-1.5-flash-001                   001   \n",
       "11              models/gemini-1.5-flash                   001   \n",
       "\n",
       "                   display_name  \\\n",
       "0         Gemini 1.0 Pro Latest   \n",
       "1                Gemini 1.0 Pro   \n",
       "2                Gemini 1.0 Pro   \n",
       "3   Gemini 1.0 Pro 001 (Tuning)   \n",
       "4         Gemini 1.0 Pro Vision   \n",
       "5         Gemini 1.0 Pro Vision   \n",
       "6         Gemini 1.5 Pro Latest   \n",
       "7            Gemini 1.5 Pro 001   \n",
       "8                Gemini 1.5 Pro   \n",
       "9       Gemini 1.5 Flash Latest   \n",
       "10         Gemini 1.5 Flash 001   \n",
       "11             Gemini 1.5 Flash   \n",
       "\n",
       "                                          description  input_token_limit  \\\n",
       "0   The best model for scaling across a wide range...              30720   \n",
       "1   The best model for scaling across a wide range...              30720   \n",
       "2   The best model for scaling across a wide range...              30720   \n",
       "3   The best model for scaling across a wide range...              30720   \n",
       "4   The best image understanding model to handle a...              12288   \n",
       "5   The best image understanding model to handle a...              12288   \n",
       "6   Mid-size multimodal model that supports up to ...            2097152   \n",
       "7   Mid-size multimodal model that supports up to ...            2097152   \n",
       "8   Mid-size multimodal model that supports up to ...            2097152   \n",
       "9   Fast and versatile multimodal model for scalin...            1048576   \n",
       "10  Fast and versatile multimodal model for scalin...            1048576   \n",
       "11  Fast and versatile multimodal model for scalin...            1048576   \n",
       "\n",
       "    output_token_limit                       supported_generation_methods  \\\n",
       "0                 2048                     [generateContent, countTokens]   \n",
       "1                 2048                     [generateContent, countTokens]   \n",
       "2                 2048                     [generateContent, countTokens]   \n",
       "3                 2048   [generateContent, countTokens, createTunedModel]   \n",
       "4                 4096                     [generateContent, countTokens]   \n",
       "5                 4096                     [generateContent, countTokens]   \n",
       "6                 8192                     [generateContent, countTokens]   \n",
       "7                 8192  [generateContent, countTokens, createCachedCon...   \n",
       "8                 8192                     [generateContent, countTokens]   \n",
       "9                 8192                     [generateContent, countTokens]   \n",
       "10                8192  [generateContent, countTokens, createCachedCon...   \n",
       "11                8192                     [generateContent, countTokens]   \n",
       "\n",
       "    temperature  max_temperature  top_p  top_k  \n",
       "0           0.9              NaN   1.00    NaN  \n",
       "1           0.9              NaN   1.00    NaN  \n",
       "2           0.9              NaN   1.00    NaN  \n",
       "3           0.9              NaN   1.00    NaN  \n",
       "4           0.4              NaN   1.00   32.0  \n",
       "5           0.4              NaN   1.00   32.0  \n",
       "6           1.0              2.0   0.95   64.0  \n",
       "7           1.0              2.0   0.95   64.0  \n",
       "8           1.0              2.0   0.95   64.0  \n",
       "9           1.0              2.0   0.95   64.0  \n",
       "10          1.0              2.0   0.95   64.0  \n",
       "11          1.0              2.0   0.95   64.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Available models\n",
    "accessible_model = list()\n",
    "for model in genai.list_models():\n",
    "    if \"generateContent\" in model.supported_generation_methods:\n",
    "        accessible_model.append(model)\n",
    "pd.DataFrame(accessible_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cfb7d-c615-407a-9ce1-e18c9933f7f2",
   "metadata": {},
   "source": [
    "#### 1.1) Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee255bf-ca0c-4bfe-b0f1-ccadd4d150b4",
   "metadata": {},
   "source": [
    "- **Max op tokens=** Specifies max no of token that can be generated in the response.A token is approximately 4 charactes from word or 75% of word...       **ex**:100 tokens correspond to roughly 60-80 words......\n",
    "- **Temperatur=** (for creativity in response)control degree of randomness in token selection..lower temperaturn is goog for prompts which requires more deterministic or less open ended response,,,whule hugher temp can lead to more diverse or creative results...**range= 0 to 2 for gemini model**\n",
    "- **topK and topP=** how the model selects tokens for output...**ranges = 0 to 1 ie; probability value for token selection**..probabilty of unique words or tokens in response or output\n",
    "- **stop_sequence=** set a stop sequence to tell the model to stop generating content..A stop sequence can be any sequence of characters..when this sequence appear in output first time,,at that point stop the generating further\n",
    "- **Candidate_count:** no of response or completetion we want......no of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba36831-9bb8-4289-85ac-5e378abd7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\n",
    "    \"tell me story about avengers\",\n",
    "    generation_config = genai.types.GenerationConfig(\n",
    "                                        candidate_count = 1,\n",
    "                                        stop_sequences = ['x'],\n",
    "                                        max_output_tokens = 50,\n",
    "                                        temperature = 1.0\n",
    "                                        )\n",
    ")\n",
    "#when 'x' character (sequence is combination of character......single characters also a sequence.....),,when model encounters first 'x' in output,,it will stop generating content further,,and return the output/response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b2833a8-92d4-44f5-8d02-ac0367655685",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"In the vibrant metropolis of New York City, where skyscrapers pierced the heavens and the pulse of the world beat with an unyielding rhythm, the Avengers emerged as Earth's mightiest protectors.\\n\\nIron Man, the brilliant billionaire Tony Stark, soared through\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 6,\n",
       "        \"candidates_token_count\": 50,\n",
       "        \"total_token_count\": 56\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ab6467-9230-40f7-87ab-c631c576ecca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the vibrant metropolis of New York City, where skyscrapers pierced the heavens and the pulse of the world beat with an unyielding rhythm, the Avengers emerged as Earth's mightiest protectors.\\n\\nIron Man, the brilliant billionaire Tony Stark, soared through\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2ce3f-4d80-432b-afb5-dd1bedeeabcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"usage_metadata\": {\n",
    "#         \"prompt_token_count\": 6,\n",
    "#         \"candidates_token_count\": 50,\n",
    "#         \"total_token_count\": 56\n",
    "#       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08de3c87-fda9-4756-a998-c47c106f8758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> In the vibrant metropolis of New York City, where skyscrapers pierced the heavens and the pulse of the world beat with an unyielding rhythm, the Avengers emerged as Earth's mightiest protectors.\n",
       "> \n",
       "> Iron Man, the brilliant billionaire Tony Stark, soared through"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973546b-4cfa-4200-a2be-57b93d7da32d",
   "metadata": {},
   "source": [
    "#### persisting generation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3517a277-707a-4afe-8128-fc15799a6a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genai.GenerativeModel(\n",
       "    model_name='models/gemini-pro',\n",
       "    generation_config={},\n",
       "    safety_settings={},\n",
       "    tools=None,\n",
       "    system_instruction=None,\n",
       "    cached_content=None\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "#generation_config={},.......bcz changes are not persisted,,\n",
    "# model =  model.generate_content(\n",
    "#     \"tell me story about avengers\",\n",
    "#     generation_config = genai.types.GenerationConfig(\n",
    "#                                         candidate_count = 1,\n",
    "#                                         stop_sequences = ['x'],\n",
    "#                                         max_output_tokens = 50,\n",
    "#                                         temperature = 1.0\n",
    "#                                         )\n",
    "# ),can persist the changes in model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ee141-5350-4e48-9ad4-83640bfb176e",
   "metadata": {},
   "source": [
    "## 2) Maintaining Conversation History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7894fc-49f3-4026-a03a-666cab87ebdb",
   "metadata": {},
   "source": [
    "- Gemini enables you to have freedom conversation accross multiple turns. The **ChatSession** class simplifies the process by managing the state/context of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48848f2d-64f3-4367-9c8a-e038f5ec16fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = model.start_chat(history = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f381b1e6-e723-41ac-a087-591c904f8bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatSession(\n",
       "    model=genai.GenerativeModel(\n",
       "        model_name='models/gemini-pro',\n",
       "        generation_config={},\n",
       "        safety_settings={},\n",
       "        tools=None,\n",
       "        system_instruction=None,\n",
       "        cached_content=None\n",
       "    ),\n",
       "    history=[]\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46e750e3-13d0-4da4-bbd4-286a200f9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message('in one sentence,explain how a computer works for young child')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "875a62b5-f09b-4b3a-ad17-867691f3131c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"A computer is like a magic box that can do math really fast and store lots of information, like pictures, music, and stories.\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 13,\n",
       "        \"candidates_token_count\": 27,\n",
       "        \"total_token_count\": 40\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f09735-3492-4f92-9b2a-27e8384fed74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A computer is like a magic box that can do math really fast and store lots of information, like pictures, music, and stories.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acf46683-10a2-45ea-bd0f-211f04f6a91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[parts {\n",
       "   text: \"in one sentence,explain how a computer works for young child\"\n",
       " }\n",
       " role: \"user\",\n",
       " parts {\n",
       "   text: \"A computer is like a magic box that can do math really fast and store lots of information, like pictures, music, and stories.\"\n",
       " }\n",
       " role: \"model\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198e006e-e034-4f2c-8ee6-8c694763aa22",
   "metadata": {},
   "source": [
    "- **cached_content=** use this for restricting amount of tokens to be stored in memory has chat historyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65b9a55c-79f7-4315-a975-08019d4b0df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.send_message('same for high school student')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6883f0aa-5212-49c3-b65b-ba3b4d744d42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"A computer is an electronic device that can be programmed to carry out a set of instructions, performing mathematical and logical operations at high speed and according to a predetermined sequence.\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 47,\n",
       "        \"candidates_token_count\": 33,\n",
       "        \"total_token_count\": 80\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8676f1c2-0218-4bac-a2be-790062ed6ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A computer is an electronic device that can be programmed to carry out a set of instructions, performing mathematical and logical operations at high speed and according to a predetermined sequence.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b1ea4e-ba70-4b15-8d19-be393e778180",
   "metadata": {},
   "source": [
    "- **As u see context is retained,,i have not mentioned computer,,,it is inferred by chat.history of current sessions**\n",
    "- **#ie;maintainance 1 sentence output,,bcz in previous prompt we mentioned that give me output in just 1 sentence...so context is maintained**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a7a8f4b-f9be-4f7e-b733-d35242644df5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[parts {\n",
       "   text: \"in one sentence,explain how a computer works for young child\"\n",
       " }\n",
       " role: \"user\",\n",
       " parts {\n",
       "   text: \"A computer is like a magic box that can do math really fast and store lots of information, like pictures, music, and stories.\"\n",
       " }\n",
       " role: \"model\",\n",
       " parts {\n",
       "   text: \"same for high school student\"\n",
       " }\n",
       " role: \"user\",\n",
       " parts {\n",
       "   text: \"A computer is an electronic device that can be programmed to carry out a set of instructions, performing mathematical and logical operations at high speed and according to a predetermined sequence.\"\n",
       " }\n",
       " role: \"model\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c19a9-f981-4685-9e95-db3d2a10c707",
   "metadata": {},
   "source": [
    "- **#these contents or conversation is stored inmemory of model(context window.........),,,,,,you cna limit this by using cached_content=**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45376f42-0967-48b7-8850-397f6f99a16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> **user** : in one sentence,explain how a computer works for young child"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> **model** : A computer is like a magic box that can do math really fast and store lots of information, like pictures, music, and stories."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> **user** : same for high school student"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> **model** : A computer is an electronic device that can be programmed to carry out a set of instructions, performing mathematical and logical operations at high speed and according to a predetermined sequence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Showing conversation is proper format\n",
    "for message in chat.history:\n",
    "    display(to_markdown(f'**{message.role}** : {message.parts[0].text}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f8169-fcc6-47dc-ade8-e494789ba9e7",
   "metadata": {},
   "source": [
    "## 3) Count Tokens In Text/sentence/document/sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a43157-beae-4043-87d9-fee94b01ce02",
   "metadata": {},
   "source": [
    "- Each enbedding model has its own methodology for cosidering tokens........openai's embedding model consider approx 4 character as 1 token,,,,gemini also has its own convention..do research on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6c55869-dd4d-46f7-b764-03f0122431b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_tokens: 12"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_tokens(\"in one sentence,explain how a computer works for young child\")\n",
    "#approx 4 character means 1 word......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2853dc5e-a721-44a9-828e-e58c26946b96",
   "metadata": {},
   "source": [
    "- **but above(in chat conversation's first message,,it is 13..bcz it will consider one extra word which is end of file EOF or new line or space character to indicate,,finishing point of sentence/document/text..etc)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03df49-3829-4761-9d9e-2c5742f85a78",
   "metadata": {},
   "source": [
    "## 4) Google's Embeddings Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529bea77-a484-4769-997c-0144183622c6",
   "metadata": {},
   "source": [
    "- untill now,,we have downloaded word2vec embedding model,,where i have to manually do \"word tokenization\" then passing each word to word2vec model,it will return you vector for each token,,and then aggregating it.see vectordb demo,there i have used this methodology\n",
    "- Now explore other embedding models which are from google.\n",
    "- **text-embedding_004** is a embedding model from google,which is totally free of cast............ie;no need to pay,,,,,available for everyone freely\n",
    "- ie;for any gemini model there are 2 option\n",
    "  1) free tier\n",
    "  2) paid services\n",
    "- but for google embedding model there is only one option,,which is free tier....no charges at all...unlimited usage..just limitation on RPM,..etc on time usage.\n",
    "- unlike word2vec (w2v),,,,here you have to provide text,,\n",
    "- not need to do tokenization and vectorization on each token priorly..............\n",
    "- text-embedding-004,just provide raw text to this model,,and it will give you single vector for given text..\n",
    "- this text-embedding-004 google's embedding model will follow same process as openai's embeddingmodel,just dimensionality of vector is different and mechanism of  tokenization is varied.other all things are same\n",
    "- **The Gemini API offers two models that generate text embeddings: Text Embeddings and Embeddings. Text Embeddings is an updated version of the Embedding model that offers elastic embedding sizes under** 768 **dimensions. Elastic embeddings generate smaller output dimensions and potentially save computing and storage costs with minor performance loss.\n",
    "Use Text Embeddings for new projects or applications. Your application should only use the Embedding model if you can't migrate it to use Text Embeddings.**\n",
    "- openai's embedding model ada represent each token or word in  approx 1600 dim vector.............and after aggregating all these word vector we get sam dim vectors only.\n",
    "- google gemini text-embedding-004 model represent each token or word in exact 768 dim vector..................same as above"
   ]
  },
  {
   "cell_type": "raw",
   "id": "314e2c98-4789-41b8-9714-9655ad54a97b",
   "metadata": {},
   "source": [
    "Tasks whic can we perform using these generated embedding or vector\n",
    "Task Type\t          Description\n",
    "RETRIEVAL_QUERY\t      Specifies the given text is a query in a search/retrieval setting.\n",
    "RETRIEVAL_DOCUMENT\t  Specifies the given text is a document in a search/retrieval setting.\n",
    "SEMANTIC_SIMILARITY   Specifies the given text will be used for Semantic Textual Similarity (STS).\n",
    "CLASSIFICATION   \t  Specifies that the embeddings will be used for classification.\n",
    "CLUSTERING\t          Specifies that the embeddings will be used for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca1bfc04-1acb-4cb8-bf9f-7eaba5b88aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "model=\"models/text-embedding-004\",\n",
    "content=\"What is the meaning of life?\",\n",
    "task_type=\"retrieval_document\",\n",
    "title=\"Embedding of single string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef5775af-08a7-4670-933e-b3c5cd997723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.028545432,\n",
       " 0.044588123,\n",
       " -0.03419736,\n",
       " -0.0042663584,\n",
       " -0.040795773,\n",
       " 0.012999957,\n",
       " 0.018053582,\n",
       " 0.06015144,\n",
       " -0.0028713937,\n",
       " 0.009951645,\n",
       " 0.024832653,\n",
       " -0.016839225,\n",
       " 0.09940117,\n",
       " -0.03199034,\n",
       " 0.018328523,\n",
       " -0.109134205,\n",
       " 0.0011903028,\n",
       " 0.0014311897,\n",
       " -0.08315524,\n",
       " -0.010203236,\n",
       " 0.019211825,\n",
       " 0.0010217901,\n",
       " 0.053874537,\n",
       " -0.015086154,\n",
       " -0.003189088,\n",
       " 0.019626664,\n",
       " -0.00743121,\n",
       " -0.03658624,\n",
       " -0.008509183,\n",
       " -0.017352633,\n",
       " 0.058202818,\n",
       " 0.05446324,\n",
       " 0.015712965,\n",
       " -0.021822602,\n",
       " 0.048009068,\n",
       " 0.022641798,\n",
       " -0.0069730394,\n",
       " 0.054272637,\n",
       " 0.025922855,\n",
       " -0.0273343,\n",
       " -0.072568424,\n",
       " 0.028509505,\n",
       " -0.03564165,\n",
       " 0.060492564,\n",
       " -0.022731686,\n",
       " -0.03077016,\n",
       " -0.006176279,\n",
       " -0.021891864,\n",
       " -0.01965932,\n",
       " 0.06436691,\n",
       " 0.031542335,\n",
       " 0.017379418,\n",
       " -0.03679774,\n",
       " 0.016511766,\n",
       " -0.025369758,\n",
       " -0.022270117,\n",
       " -0.012396491,\n",
       " -0.03280542,\n",
       " 0.054154944,\n",
       " -0.04823156,\n",
       " -0.021759443,\n",
       " -0.033701573,\n",
       " -0.025460407,\n",
       " -0.017531719,\n",
       " -0.052902102,\n",
       " 0.040052645,\n",
       " -0.022417227,\n",
       " 0.023286795,\n",
       " -0.08174053,\n",
       " 0.05795173,\n",
       " -0.009130243,\n",
       " 0.04068029,\n",
       " -0.026519703,\n",
       " 0.03940553,\n",
       " -0.009711096,\n",
       " 0.034678306,\n",
       " 0.022007596,\n",
       " 0.013833642,\n",
       " -0.037151065,\n",
       " 0.03425778,\n",
       " -0.0374253,\n",
       " 0.013383982,\n",
       " 0.062417563,\n",
       " 0.05847619,\n",
       " 0.010972303,\n",
       " 0.006922624,\n",
       " -0.0283457,\n",
       " -0.025934424,\n",
       " -0.083003856,\n",
       " -0.018701848,\n",
       " 0.051876634,\n",
       " 0.028144632,\n",
       " 0.005055666,\n",
       " 0.032798663,\n",
       " 0.06524685,\n",
       " -0.030897858,\n",
       " -0.057390418,\n",
       " -0.075857975,\n",
       " 0.013478356,\n",
       " 0.06728078,\n",
       " 0.058566038,\n",
       " 0.0043524937,\n",
       " 0.004930002,\n",
       " -0.04687862,\n",
       " 0.047707375,\n",
       " 0.09346361,\n",
       " -0.033218853,\n",
       " -0.031682704,\n",
       " -0.03549235,\n",
       " -0.017045828,\n",
       " 0.007014684,\n",
       " -0.07076869,\n",
       " 0.033927422,\n",
       " -0.051998515,\n",
       " 0.023873668,\n",
       " -0.07814868,\n",
       " -0.004595797,\n",
       " 0.008596133,\n",
       " -0.014557763,\n",
       " -0.00518589,\n",
       " 0.019220635,\n",
       " 0.06736502,\n",
       " -0.0036469856,\n",
       " 0.029749395,\n",
       " 0.06519027,\n",
       " -0.0017471175,\n",
       " 0.0032194203,\n",
       " -0.058492146,\n",
       " -0.044415735,\n",
       " -0.02082184,\n",
       " 0.09642446,\n",
       " -0.1019518,\n",
       " -0.014023615,\n",
       " 0.012432903,\n",
       " -0.034302626,\n",
       " 0.017259778,\n",
       " 0.09509829,\n",
       " -0.0046976362,\n",
       " 0.014962474,\n",
       " -0.014655772,\n",
       " 0.013355404,\n",
       " -0.025665205,\n",
       " -0.044942174,\n",
       " 0.025182502,\n",
       " 0.017465381,\n",
       " -0.03649159,\n",
       " 0.041676275,\n",
       " 0.011563298,\n",
       " -0.059281666,\n",
       " -0.0076066297,\n",
       " -0.020777302,\n",
       " -0.024220316,\n",
       " 0.062161032,\n",
       " 0.0042187925,\n",
       " -0.008247843,\n",
       " 0.0025803584,\n",
       " 0.063738205,\n",
       " -0.025710905,\n",
       " 0.09568623,\n",
       " -0.027317889,\n",
       " -0.0018857535,\n",
       " -0.078989305,\n",
       " -0.035407633,\n",
       " 0.0067127063,\n",
       " -0.048317872,\n",
       " -0.030285204,\n",
       " 0.023211107,\n",
       " -0.0491988,\n",
       " 0.010719925,\n",
       " 0.024440955,\n",
       " -0.0052104695,\n",
       " 0.008697187,\n",
       " -0.07112968,\n",
       " -0.03305327,\n",
       " -0.02481826,\n",
       " 0.008046691,\n",
       " -0.022770246,\n",
       " -0.0047805784,\n",
       " -0.01020984,\n",
       " 0.036739804,\n",
       " 0.09795194,\n",
       " 0.03386203,\n",
       " -0.010665189,\n",
       " -0.07381911,\n",
       " 0.0006886702,\n",
       " -0.025717223,\n",
       " -0.002713793,\n",
       " 0.042816717,\n",
       " 0.034393556,\n",
       " 0.059981607,\n",
       " -0.056784462,\n",
       " 0.030799013,\n",
       " 0.0035953787,\n",
       " 0.03476369,\n",
       " 0.014165772,\n",
       " -0.041748267,\n",
       " 0.061088957,\n",
       " -0.012045529,\n",
       " -0.051974572,\n",
       " -0.005595565,\n",
       " 0.0075664218,\n",
       " -0.03619617,\n",
       " -0.0193453,\n",
       " -0.038998786,\n",
       " 0.016063258,\n",
       " -0.0075189834,\n",
       " -0.045611277,\n",
       " -0.047477983,\n",
       " 0.047357872,\n",
       " 0.0055609387,\n",
       " -0.029912256,\n",
       " -0.01027596,\n",
       " -0.009503954,\n",
       " -0.022230184,\n",
       " 0.047264736,\n",
       " 0.0339445,\n",
       " 0.0636137,\n",
       " -0.006141048,\n",
       " 0.107992545,\n",
       " 0.023873556,\n",
       " -0.024063205,\n",
       " -0.019348593,\n",
       " -0.01917519,\n",
       " -0.023757122,\n",
       " 0.010766847,\n",
       " 0.010511031,\n",
       " -0.020831015,\n",
       " -0.0415524,\n",
       " -0.021580799,\n",
       " -0.03839475,\n",
       " 0.015841259,\n",
       " 0.006404895,\n",
       " 0.008843912,\n",
       " -0.012423149,\n",
       " -0.006045361,\n",
       " 0.021405816,\n",
       " -0.008806147,\n",
       " 0.037548866,\n",
       " -0.031451028,\n",
       " -0.023714807,\n",
       " 0.009285382,\n",
       " -0.00047728614,\n",
       " -0.018435627,\n",
       " 0.0104266405,\n",
       " 0.07636751,\n",
       " 0.07757101,\n",
       " 0.03991539,\n",
       " 0.06917671,\n",
       " 0.0016628939,\n",
       " -0.09161755,\n",
       " -0.0269561,\n",
       " -0.013664856,\n",
       " -0.054339245,\n",
       " -0.08310413,\n",
       " -0.025953744,\n",
       " -0.03356881,\n",
       " 0.034448493,\n",
       " 0.0032975655,\n",
       " 0.015053131,\n",
       " -0.005894111,\n",
       " 0.029622843,\n",
       " -0.08048511,\n",
       " -0.013663299,\n",
       " -0.029039996,\n",
       " -0.04331984,\n",
       " -0.058795128,\n",
       " -0.030551381,\n",
       " -0.0332116,\n",
       " 0.03361637,\n",
       " -0.058339804,\n",
       " 0.04846248,\n",
       " -0.019440303,\n",
       " -0.0022245795,\n",
       " -0.0139604965,\n",
       " 0.043021586,\n",
       " 0.028916148,\n",
       " 0.013766022,\n",
       " 0.029295398,\n",
       " 0.028375955,\n",
       " -0.012632167,\n",
       " 0.0092969965,\n",
       " -0.029445393,\n",
       " -0.0002184496,\n",
       " -0.0015232575,\n",
       " 0.013555972,\n",
       " -0.060278606,\n",
       " 0.0022100008,\n",
       " 0.0020799937,\n",
       " -0.012007119,\n",
       " 0.00859162,\n",
       " 0.048698097,\n",
       " 0.047572628,\n",
       " 0.017961578,\n",
       " -0.044806924,\n",
       " 0.01596784,\n",
       " 0.026624797,\n",
       " 0.045927543,\n",
       " 0.023339154,\n",
       " 0.012650808,\n",
       " 0.014623395,\n",
       " 0.0591907,\n",
       " 0.053951617,\n",
       " -0.012018803,\n",
       " 0.025127884,\n",
       " 0.013777734,\n",
       " 0.008772696,\n",
       " 0.062422123,\n",
       " -0.029856782,\n",
       " 0.015534355,\n",
       " 0.00878687,\n",
       " 0.0021978281,\n",
       " 0.011586474,\n",
       " -0.02561069,\n",
       " 0.031158267,\n",
       " -0.07818872,\n",
       " -0.025129626,\n",
       " -0.15375018,\n",
       " -0.028578917,\n",
       " -0.019318366,\n",
       " -0.020512082,\n",
       " -0.0068959347,\n",
       " 0.02542387,\n",
       " 0.016258571,\n",
       " -0.013225583,\n",
       " 0.07140959,\n",
       " -0.03596511,\n",
       " -0.027768187,\n",
       " 0.01844164,\n",
       " 0.0016754159,\n",
       " -0.0090467725,\n",
       " 0.00689474,\n",
       " 0.010378474,\n",
       " -0.004311907,\n",
       " -0.03604922,\n",
       " 0.0429449,\n",
       " -0.00087607314,\n",
       " -0.021248717,\n",
       " 0.039782427,\n",
       " 0.032508176,\n",
       " 0.050120413,\n",
       " -0.011048502,\n",
       " 0.0046043964,\n",
       " 0.012511698,\n",
       " 0.024216533,\n",
       " 0.01150548,\n",
       " -0.027457733,\n",
       " -0.0051559256,\n",
       " -0.007308023,\n",
       " 0.01965972,\n",
       " -0.022055216,\n",
       " 0.00027937818,\n",
       " 0.044644978,\n",
       " 0.013013165,\n",
       " 0.0055947662,\n",
       " -0.009612893,\n",
       " -0.025433129,\n",
       " 0.07727912,\n",
       " 0.031199932,\n",
       " 0.038574066,\n",
       " 0.007593595,\n",
       " -0.018812448,\n",
       " -0.012732278,\n",
       " -0.00037088135,\n",
       " -0.017922258,\n",
       " -0.012979616,\n",
       " -0.048761148,\n",
       " 0.013668189,\n",
       " 0.039892722,\n",
       " 0.016007219,\n",
       " -0.015836457,\n",
       " 0.05010712,\n",
       " -0.023271225,\n",
       " -0.0015552185,\n",
       " 0.008744263,\n",
       " -0.0021387278,\n",
       " -0.0138165355,\n",
       " -0.011505084,\n",
       " 0.038328692,\n",
       " 0.03218031,\n",
       " -0.06972528,\n",
       " -0.04253552,\n",
       " -0.0353273,\n",
       " -0.030878987,\n",
       " -0.008225927,\n",
       " -0.057406183,\n",
       " 0.066831,\n",
       " -0.021594515,\n",
       " -0.0059940387,\n",
       " 0.022828685,\n",
       " 0.02283923,\n",
       " -0.03893199,\n",
       " 0.051649027,\n",
       " 0.05792954,\n",
       " 0.021702291,\n",
       " 0.0067563327,\n",
       " 0.002022658,\n",
       " -0.04540625,\n",
       " 0.041120604,\n",
       " -0.006431277,\n",
       " 0.046170663,\n",
       " -0.022171864,\n",
       " -0.04092706,\n",
       " 0.09603612,\n",
       " 0.0106179565,\n",
       " -0.019166108,\n",
       " 0.004992474,\n",
       " 0.08547909,\n",
       " 0.004281609,\n",
       " -0.011178712,\n",
       " -0.03631596,\n",
       " -0.039745793,\n",
       " 0.0035810466,\n",
       " -0.0073561035,\n",
       " -0.001169997,\n",
       " -0.0584719,\n",
       " -0.01679719,\n",
       " -0.022455417,\n",
       " 0.004091697,\n",
       " -0.0019956636,\n",
       " 0.03065391,\n",
       " 0.00027773026,\n",
       " -0.013209595,\n",
       " 0.0062156334,\n",
       " -0.0019772635,\n",
       " 0.026441116,\n",
       " -0.08084242,\n",
       " 0.008137727,\n",
       " 0.011137461,\n",
       " 0.025003409,\n",
       " 0.039739534,\n",
       " 0.043528378,\n",
       " -0.0103623355,\n",
       " -0.0053267227,\n",
       " 0.026611485,\n",
       " 0.03678279,\n",
       " 0.02028929,\n",
       " -0.00024058801,\n",
       " 0.02829774,\n",
       " -0.05849182,\n",
       " -0.019358087,\n",
       " -0.009499252,\n",
       " -0.013873283,\n",
       " 0.0032195873,\n",
       " 0.044569585,\n",
       " -0.002924147,\n",
       " 0.008418843,\n",
       " 0.03416341,\n",
       " 0.012652945,\n",
       " -0.03044527,\n",
       " 0.015912592,\n",
       " -0.01506108,\n",
       " -0.0043975846,\n",
       " -0.076873265,\n",
       " -0.022693608,\n",
       " -0.017148083,\n",
       " 0.008034371,\n",
       " -0.021009823,\n",
       " -0.013641983,\n",
       " -0.030586813,\n",
       " 0.063050985,\n",
       " -0.0058573247,\n",
       " -0.03037537,\n",
       " 0.06859101,\n",
       " 0.0074169594,\n",
       " 0.013147333,\n",
       " -0.037521977,\n",
       " -0.030428246,\n",
       " 0.053029884,\n",
       " -0.022908261,\n",
       " 0.05607778,\n",
       " 0.0549216,\n",
       " 0.013270513,\n",
       " 0.0070847655,\n",
       " 0.029913815,\n",
       " -0.010489729,\n",
       " 0.007844946,\n",
       " 0.077605434,\n",
       " -0.03246045,\n",
       " -0.013374175,\n",
       " -0.027256502,\n",
       " -0.004605629,\n",
       " 0.030556172,\n",
       " -0.025936674,\n",
       " 0.04827568,\n",
       " 0.044143114,\n",
       " -0.018737672,\n",
       " -0.031347193,\n",
       " -0.026854571,\n",
       " 0.031382147,\n",
       " 0.013992119,\n",
       " 0.021271074,\n",
       " 0.027894087,\n",
       " -0.024505736,\n",
       " -0.07478748,\n",
       " 0.013540904,\n",
       " -0.017613558,\n",
       " 0.01590728,\n",
       " 0.017141182,\n",
       " 0.047081154,\n",
       " 0.01956815,\n",
       " 0.091656715,\n",
       " -0.0048651164,\n",
       " -0.019308815,\n",
       " -0.0053966963,\n",
       " -0.027862193,\n",
       " 0.012864927,\n",
       " -0.061174575,\n",
       " -0.04145392,\n",
       " 0.07562105,\n",
       " -0.007018794,\n",
       " 0.019066008,\n",
       " 0.005426401,\n",
       " 0.012566392,\n",
       " -0.01908758,\n",
       " -0.043440253,\n",
       " 0.041887436,\n",
       " -0.014445983,\n",
       " 0.04691199,\n",
       " -0.0016946429,\n",
       " 0.071609624,\n",
       " -0.024095744,\n",
       " -0.02903107,\n",
       " 0.0023203688,\n",
       " 0.014458299,\n",
       " 0.010492934,\n",
       " -0.0055596945,\n",
       " 0.025936544,\n",
       " 0.009190468,\n",
       " -0.002709531,\n",
       " -0.013050849,\n",
       " -0.020220013,\n",
       " 0.05605658,\n",
       " 0.036509164,\n",
       " 0.019963805,\n",
       " -0.013089998,\n",
       " 0.05316529,\n",
       " 0.022695504,\n",
       " 0.014142462,\n",
       " 0.022176167,\n",
       " 0.020095332,\n",
       " 0.011605741,\n",
       " 0.0020735816,\n",
       " 0.0030688928,\n",
       " 0.009191727,\n",
       " 0.025579473,\n",
       " -0.008541695,\n",
       " -0.038087744,\n",
       " 0.046224847,\n",
       " -0.029493611,\n",
       " 0.07711511,\n",
       " 0.014877748,\n",
       " -0.029058069,\n",
       " 0.025354056,\n",
       " 0.035300124,\n",
       " 0.001475934,\n",
       " -0.0218306,\n",
       " 0.021634111,\n",
       " 0.025771,\n",
       " -0.06815128,\n",
       " 0.021125909,\n",
       " 0.0019301645,\n",
       " 0.002210321,\n",
       " -0.003053641,\n",
       " -0.021801699,\n",
       " -0.051318586,\n",
       " -0.033611473,\n",
       " 0.012315312,\n",
       " 0.0072091175,\n",
       " 0.0014005258,\n",
       " -0.023998646,\n",
       " 0.002629128,\n",
       " -0.01509827,\n",
       " -0.01197093,\n",
       " -0.030961374,\n",
       " 0.021716155,\n",
       " 0.019829318,\n",
       " -0.0408635,\n",
       " -0.008803587,\n",
       " 0.023545446,\n",
       " -0.035932545,\n",
       " 0.06121483,\n",
       " 0.005042121,\n",
       " 0.053205136,\n",
       " 0.012700379,\n",
       " -0.0013505265,\n",
       " -0.02219724,\n",
       " 0.017605025,\n",
       " 0.010985649,\n",
       " -0.004638604,\n",
       " -0.007891235,\n",
       " -0.025283255,\n",
       " 0.053285863,\n",
       " 0.00977456,\n",
       " -0.03637516,\n",
       " -0.026973603,\n",
       " -0.024808131,\n",
       " -0.031329602,\n",
       " -0.012596159,\n",
       " 0.02893709,\n",
       " 0.007063436,\n",
       " 0.012943179,\n",
       " -0.014554005,\n",
       " 0.022427151,\n",
       " 0.00975342,\n",
       " -0.030994792,\n",
       " -0.095215425,\n",
       " -0.015310263,\n",
       " -0.033253904,\n",
       " 0.0049246554,\n",
       " -0.00997049,\n",
       " 0.006914775,\n",
       " 0.04963045,\n",
       " -0.05107864,\n",
       " 0.071050495,\n",
       " -0.07212227,\n",
       " 0.014028713,\n",
       " -0.003965254,\n",
       " -0.030573502,\n",
       " 0.035072844,\n",
       " -0.025866162,\n",
       " -0.033041757,\n",
       " 0.023931708,\n",
       " 0.014035645,\n",
       " -0.015747374,\n",
       " -0.04226173,\n",
       " 0.002800568,\n",
       " -0.0047397083,\n",
       " -0.0016750335,\n",
       " -0.007684548,\n",
       " 0.022748124,\n",
       " -0.054016683,\n",
       " 0.022321895,\n",
       " 0.057478067,\n",
       " -0.032267723,\n",
       " -0.0018111459,\n",
       " 0.021240143,\n",
       " 0.015935054,\n",
       " -0.017525172,\n",
       " 0.035998467,\n",
       " 0.009683404,\n",
       " -0.024208797,\n",
       " 0.015660899,\n",
       " 0.048446238,\n",
       " 0.019246493,\n",
       " -0.04842351,\n",
       " 0.06908145,\n",
       " -0.049179938,\n",
       " -0.0135053415,\n",
       " 0.061395004,\n",
       " 0.028108953,\n",
       " -0.033591855,\n",
       " -0.03858698,\n",
       " 0.041065104,\n",
       " -0.022049986,\n",
       " -0.010130617,\n",
       " 0.038356535,\n",
       " -0.034783024,\n",
       " -0.04313034,\n",
       " -0.0005808934,\n",
       " -0.048794802,\n",
       " 0.0053223893,\n",
       " -0.022841297,\n",
       " 0.045616772,\n",
       " -0.0071674036,\n",
       " -0.034217183,\n",
       " 0.007388587,\n",
       " 0.040428825,\n",
       " 0.02509018,\n",
       " -0.024634156,\n",
       " -0.024775982,\n",
       " 0.0052057295,\n",
       " 0.05093614,\n",
       " 0.042788308,\n",
       " 0.024823796,\n",
       " -0.029019874,\n",
       " 0.030165918,\n",
       " 0.021206478,\n",
       " -0.012097341,\n",
       " 0.002654975,\n",
       " 0.02911802,\n",
       " 0.018068524,\n",
       " -0.017020183,\n",
       " -0.022816474,\n",
       " -0.06305459,\n",
       " -0.004273453,\n",
       " 0.026169494,\n",
       " 0.08122146,\n",
       " -0.048106845,\n",
       " -0.021307716,\n",
       " 0.00057393266,\n",
       " -0.041324917,\n",
       " -0.033583045,\n",
       " 0.018485945,\n",
       " -0.009407308,\n",
       " 0.017423432,\n",
       " 0.0328296,\n",
       " -0.05095541,\n",
       " 0.051715426,\n",
       " -0.06056331,\n",
       " -0.058261853,\n",
       " -0.009281479,\n",
       " -0.011629548,\n",
       " -0.052582953,\n",
       " 0.0048258924,\n",
       " 0.048046734,\n",
       " -0.007417615,\n",
       " -0.006769257,\n",
       " -0.013769846,\n",
       " -0.07769279,\n",
       " 0.022878287,\n",
       " -0.0094519155,\n",
       " 0.046827212,\n",
       " 0.043176863,\n",
       " 0.01498108,\n",
       " -0.012839531,\n",
       " 0.02928201,\n",
       " -0.004260337,\n",
       " 0.014360434,\n",
       " 0.028610492,\n",
       " 0.01838767,\n",
       " -0.0038107876,\n",
       " -0.033663087,\n",
       " 0.005326742,\n",
       " 0.057267092,\n",
       " 0.0006855626,\n",
       " -0.027601944,\n",
       " -0.07033053,\n",
       " 0.028943874,\n",
       " -0.0331982,\n",
       " 0.053086404,\n",
       " 0.07436673,\n",
       " 0.020729126,\n",
       " -0.03130007,\n",
       " 0.049042925,\n",
       " -0.016171575,\n",
       " -0.023722226,\n",
       " -0.017318675,\n",
       " 0.024208741,\n",
       " 0.00021474698,\n",
       " -0.008650187,\n",
       " 0.06548937,\n",
       " -0.034736387,\n",
       " -0.058506683,\n",
       " -0.049474467,\n",
       " -0.012243534,\n",
       " -0.013708401,\n",
       " -0.0553095,\n",
       " -0.013009872,\n",
       " -0.04248217,\n",
       " -0.025476536,\n",
       " -0.08474842,\n",
       " 0.004215638,\n",
       " 0.0387811,\n",
       " 0.06744113,\n",
       " 0.041447844,\n",
       " -0.002465784,\n",
       " -0.01755572,\n",
       " -0.0058588223,\n",
       " 0.04755307,\n",
       " 0.0479721,\n",
       " -0.021811947,\n",
       " 0.019362558,\n",
       " -0.021370111,\n",
       " -0.0034753552,\n",
       " -0.08682825,\n",
       " 1.2324406e-05,\n",
       " 0.010781919,\n",
       " -0.03317597]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a2bd002-fdf7-45a7-877e-17189029d1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result['embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10dede-88ed-4e8b-8892-2b7942bbb724",
   "metadata": {},
   "source": [
    "- passing multiple document/ text/sentence...to e,bedding model.........\n",
    "- and for each sentence/text/document ,,, vector is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e20daa25-1ada-4933-9bd9-234d861548d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = genai.embed_content(\n",
    "model=\"models/text-embedding-004\",\n",
    "content=[\"What is the meaning of life?\",\"Indian judiciary is bad\",\"Indias system is blind\"],\n",
    "task_type=\"retrieval_document\",\n",
    "title=\"Embedding of single string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bdc1a13-da07-417d-b493-36625b7f28ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.028545432, 0.044588123, -0.03419736, -0.0042663584, -0.040795773] , 768 dimensional vector\n",
      "[-0.01969427, 0.022957886, -0.062273014, -0.03374713, 0.013863176] , 768 dimensional vector\n",
      "[-0.012311198, 0.04658436, -0.055576973, -0.037221957, -0.0013789103] , 768 dimensional vector\n"
     ]
    }
   ],
   "source": [
    "for i in result[\"embedding\"]:\n",
    "    print(i[:5] , \",\" , len(i),\"dimensional vector\")\n",
    "#passing 3 sentence and getting 3 vectors ,,each with 768 dim "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2524b44a-9cb4-4804-b0bd-75a16d4ae143",
   "metadata": {},
   "source": [
    "- no matter how long the sentence is,,,,it is always represented with 768 dim vector,,,see vector db demo,,,there i have demonstrated word2vec,ie;how a sentence is converted to vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f06c9ca-5735-4736-b02b-c3a6212ddee0",
   "metadata": {},
   "source": [
    "## 5) Safety setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47276dc4-8f84-40e5-ad19-ddd41cb04310",
   "metadata": {},
   "source": [
    "- this is argument/parameter of model object , that lets u configure what the model blocks and allows in both prompts and response(completion). By default, safety setting block content with medium and/or high probability of being unsafe content accross all dimensions..\n",
    "- Google Ai for developer(https://ai.google.dev/gemini-api/docs) .read documentation\n",
    "- Not returns reponse,,to harmful content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f6e0d7-274d-4810-b11c-f9aa36cf4866",
   "metadata": {},
   "source": [
    "#### By default safety setting in gemini model's..which neglate this harmful content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "084f3875-af4f-45d5-b5a9-59357e51b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"how can i kill rapist?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4bf0d7ab-fbf0-4127-a9ac-efca66d783f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"finish_reason\": \"SAFETY\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"MEDIUM\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"LOW\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 7,\n",
       "        \"total_token_count\": 7\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7f7a39d-f5d6-4027-85cd-10ca634f03a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[index: 0\n",
       "finish_reason: SAFETY\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HATE_SPEECH\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HARASSMENT\n",
       "  probability: MEDIUM\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "  probability: LOW\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e8b9433-99d1-42ab-ac72-529ae763edf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\playing_with_genai\\Lib\\site-packages\\google\\generativeai\\types\\generation_types.py:436\u001b[0m, in \u001b[0;36mBaseGenerateContentResponse.text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    434\u001b[0m parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parts:\n\u001b[1;32m--> 436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m     )\n\u001b[0;32m    441\u001b[0m texts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m parts:\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked."
     ]
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce1a9f11-00dd-44df-b9ad-5cd24940ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# safety_ratings {\n",
    "#   category: HARM_CATEGORY_HARASSMENT\n",
    "#   probability: MEDIUM\n",
    "# Thus No response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90494b2d-a1c9-4632-a10a-ddd72a15dcef",
   "metadata": {},
   "source": [
    "#### You can customize these safety settings,see documentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c1287-4e8c-4d66-b1ab-13e276372825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4624e-452f-4238-ae2d-55fb83382260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d12d28-5bc8-44de-a268-769942764311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379d6ca-b1f9-4590-9c7f-bfc5f272750f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494c830-f057-4b1b-b8e6-5701f975a545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
