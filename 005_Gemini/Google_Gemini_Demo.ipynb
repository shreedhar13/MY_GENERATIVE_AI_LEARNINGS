{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55664044-8899-41e7-a3dc-ecc326c168f1",
   "metadata": {},
   "source": [
    "- Open **Google AI for Developer** , and Understand every concept that tells how to use gemini API in your application\n",
    "- The Gemini API lets you access the latest generative models from Google. This API reference provides detailed information for the classes and methods available in the Gemini API SDKs. Pick a language and follow the setup steps to get started with building generative applications on your platform of choice.\n",
    "- The Python SDK for the Gemini API is contained in the google-generativeai package. Install the dependency using **pip install -q -U google-generativeai**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96797a90-c766-4d65-943a-c2396ca0e8a7",
   "metadata": {},
   "source": [
    "- Google Provides free tier for usage of genai model........\n",
    "- **Price(input) and Price (output)**: Free of charge.....but there is a limitation ie;For gemin 1.5 flash ,, **total input token count is 1,048,576 and output tokens count is 8192** , for gemin 1.5 pro model total **input tokens count is 2,097,152 , output token count is 8192** , for gemini 1.0 pro **total ip token count is 30,720 , op token count is 2048**\n",
    "- if ypu exceed this then,, your free tier for this account is completed,,now you have to pay-as-you-go\n",
    "- **Trick:** Create another gmail account and from that generate APi and use it,,,,,,,,,,,BUt when you developing industry level application,then you have to use paid-services,,\n",
    "- **SO,I am going to use gemini 1.0 pro for learning purpose,and for project purpose i will use 1.5 pro or flash**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b907d32-e2e0-4816-b750-32b65c22758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai #For accessing Gemini API or google genai model's\n",
    "import pathlib\n",
    "import textwrap        #for text refining  or display output in precise manner             \n",
    "from IPython.display import display #for text refining  \n",
    "from IPython.display import Markdown #for text refining  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf8a73-ae6f-456a-b644-6fa45e09ce57",
   "metadata": {},
   "source": [
    "## 1) Setting GEMINI_API_KEY in system environmental variable and Accessing To connect with Google's GenAI model's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37fb5c9-7aeb-47a9-8bd3-4779c1cdfece",
   "metadata": {},
   "source": [
    "- see this video https://www.youtube.com/watch?v=hgXJia5WxtY&t=180s for storing API key in system environmental varibale\n",
    "- see this video to store API key in .env file https://www.youtube.com/watch?v=qgT-quk3JEo\n",
    "- **NOTE**: After setting the API key in .env file OR in system env ,,you have to restart the jupyter kernel ie; you have to close it and restart it otherwise ,,os will not fetch this variable,,,,,in VS code there is no such a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88022fa8-82c0-4e89-a2eb-afd78ee45091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "google_gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "#print(google_gemini_api_key)  -> gives u \"None\" means,,environmental variable not fetched by os,,so restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7162378-f8be-401c-b7a5-46d5373d8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key = google_gemini_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73522e2-3189-4ade-b06c-dfe1829557b8",
   "metadata": {},
   "source": [
    "## 2) Response formatting technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06f2cd6-9c3c-4e02-bee5-ca502fcda4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#windows + semicolon to open emoji and special symbol keypad\n",
    "def to_markdown(text):\n",
    "    text = text.replace(\"•\",\"  *\")\n",
    "    return Markdown(textwrap.indent(text,'> ', predicate = lambda _:True))\n",
    "\n",
    "#Bcz Gemini returns response containing bullet points,,so to convert it to star,,we defined this func\n",
    "#bcz models repsonse contains,,\\n , bullet poits..etc psecial symbol,,so to manage it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53b3b86-e1c2-4fc0-a8c6-48169c51b1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> This is a   * sample text with bullet points."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_text = \"This is a • sample text with bullet points.\"\n",
    "result = to_markdown(input_text)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8059335-fe69-42b6-8141-e74f7117f678",
   "metadata": {},
   "source": [
    "## 3) Checking googles GenAI model's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba78771a-0915-4ddc-bbda-5016b026a46b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/chat-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 Chat (Legacy)',\n",
      "      description='A legacy text-only model optimized for chat conversations',\n",
      "      input_token_limit=4096,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
      "      temperature=0.25,\n",
      "      max_temperature=None,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/text-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 (Legacy)',\n",
      "      description='A legacy model that understands text and generates text as an output',\n",
      "      input_token_limit=8196,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
      "      temperature=0.7,\n",
      "      max_temperature=None,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/embedding-gecko-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding Gecko',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=1024,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Latest',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
      "                   'model.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
      "                   'model that supports tuning.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
      "      temperature=0.9,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-vision-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/gemini-pro-vision',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/gemini-1.5-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro Latest',\n",
      "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro 001',\n",
      "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro',\n",
      "      description='Mid-size multimodal model that supports up to 2 million tokens',\n",
      "      input_token_limit=2097152,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash Latest',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash 001',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/embedding-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding 001',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/text-embedding-004',\n",
      "      base_model_id='',\n",
      "      version='004',\n",
      "      display_name='Text Embedding 004',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      max_temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/aqa',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Model that performs Attributed Question Answering.',\n",
      "      description=('Model trained to return answers to questions that are grounded in provided '\n",
      "                   'sources, along with estimating answerable probability.'),\n",
      "      input_token_limit=7168,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateAnswer'],\n",
      "      temperature=0.2,\n",
      "      max_temperature=None,\n",
      "      top_p=1.0,\n",
      "      top_k=40)\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    print(model)\n",
    "#These are the model we can access in free tier,and tokens limit in free tier for each model is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1246b22-a26d-4bcb-85b3-b17fe58ba070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(name='models/chat-bison-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='PaLM 2 Chat (Legacy)',\n",
       "       description='A legacy text-only model optimized for chat conversations',\n",
       "       input_token_limit=4096,\n",
       "       output_token_limit=1024,\n",
       "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
       "       temperature=0.25,\n",
       "       max_temperature=None,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/text-bison-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='PaLM 2 (Legacy)',\n",
       "       description='A legacy model that understands text and generates text as an output',\n",
       "       input_token_limit=8196,\n",
       "       output_token_limit=1024,\n",
       "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
       "       temperature=0.7,\n",
       "       max_temperature=None,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/embedding-gecko-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Embedding Gecko',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=1024,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-1.0-pro-latest',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.0 Pro Latest',\n",
       "       description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
       "                    'model.'),\n",
       "       input_token_limit=30720,\n",
       "       output_token_limit=2048,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=0.9,\n",
       "       max_temperature=None,\n",
       "       top_p=1.0,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-1.0-pro',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.0 Pro',\n",
       "       description='The best model for scaling across a wide range of tasks',\n",
       "       input_token_limit=30720,\n",
       "       output_token_limit=2048,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=0.9,\n",
       "       max_temperature=None,\n",
       "       top_p=1.0,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-pro',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.0 Pro',\n",
       "       description='The best model for scaling across a wide range of tasks',\n",
       "       input_token_limit=30720,\n",
       "       output_token_limit=2048,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=0.9,\n",
       "       max_temperature=None,\n",
       "       top_p=1.0,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-1.0-pro-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
       "       description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
       "                    'model that supports tuning.'),\n",
       "       input_token_limit=30720,\n",
       "       output_token_limit=2048,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
       "       temperature=0.9,\n",
       "       max_temperature=None,\n",
       "       top_p=1.0,\n",
       "       top_k=None),\n",
       " Model(name='models/gemini-1.0-pro-vision-latest',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.0 Pro Vision',\n",
       "       description='The best image understanding model to handle a broad range of applications',\n",
       "       input_token_limit=12288,\n",
       "       output_token_limit=4096,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=0.4,\n",
       "       max_temperature=None,\n",
       "       top_p=1.0,\n",
       "       top_k=32),\n",
       " Model(name='models/gemini-pro-vision',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.0 Pro Vision',\n",
       "       description='The best image understanding model to handle a broad range of applications',\n",
       "       input_token_limit=12288,\n",
       "       output_token_limit=4096,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=0.4,\n",
       "       max_temperature=None,\n",
       "       top_p=1.0,\n",
       "       top_k=32),\n",
       " Model(name='models/gemini-1.5-pro-latest',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Pro Latest',\n",
       "       description='Mid-size multimodal model that supports up to 2 million tokens',\n",
       "       input_token_limit=2097152,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-1.5-pro-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Pro 001',\n",
       "       description='Mid-size multimodal model that supports up to 2 million tokens',\n",
       "       input_token_limit=2097152,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-1.5-pro',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Pro',\n",
       "       description='Mid-size multimodal model that supports up to 2 million tokens',\n",
       "       input_token_limit=2097152,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-1.5-flash-latest',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Flash Latest',\n",
       "       description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-1.5-flash-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Flash 001',\n",
       "       description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-1.5-flash',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Flash',\n",
       "       description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       max_temperature=2.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/embedding-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Embedding 001',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=2048,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedContent'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/text-embedding-004',\n",
       "       base_model_id='',\n",
       "       version='004',\n",
       "       display_name='Text Embedding 004',\n",
       "       description='Obtain a distributed representation of a text.',\n",
       "       input_token_limit=2048,\n",
       "       output_token_limit=1,\n",
       "       supported_generation_methods=['embedContent'],\n",
       "       temperature=None,\n",
       "       max_temperature=None,\n",
       "       top_p=None,\n",
       "       top_k=None),\n",
       " Model(name='models/aqa',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Model that performs Attributed Question Answering.',\n",
       "       description=('Model trained to return answers to questions that are grounded in provided '\n",
       "                    'sources, along with estimating answerable probability.'),\n",
       "       input_token_limit=7168,\n",
       "       output_token_limit=1024,\n",
       "       supported_generation_methods=['generateAnswer'],\n",
       "       temperature=0.2,\n",
       "       max_temperature=None,\n",
       "       top_p=1.0,\n",
       "       top_k=40)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = list(genai.list_models())\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6caa37a-e5b0-4da4-a5e1-770cab39b5d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>base_model_id</th>\n",
       "      <th>version</th>\n",
       "      <th>display_name</th>\n",
       "      <th>description</th>\n",
       "      <th>input_token_limit</th>\n",
       "      <th>output_token_limit</th>\n",
       "      <th>supported_generation_methods</th>\n",
       "      <th>temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>models/chat-bison-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>PaLM 2 Chat (Legacy)</td>\n",
       "      <td>A legacy text-only model optimized for chat co...</td>\n",
       "      <td>4096</td>\n",
       "      <td>1024</td>\n",
       "      <td>[generateMessage, countMessageTokens]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>models/text-bison-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>PaLM 2 (Legacy)</td>\n",
       "      <td>A legacy model that understands text and gener...</td>\n",
       "      <td>8196</td>\n",
       "      <td>1024</td>\n",
       "      <td>[generateText, countTextTokens, createTunedTex...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.95</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>models/embedding-gecko-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Embedding Gecko</td>\n",
       "      <td>Obtain a distributed representation of a text.</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>[embedText, countTextTokens]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>models/gemini-1.0-pro-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro Latest</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>models/gemini-1.0-pro</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>models/gemini-pro</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>models/gemini-1.0-pro-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro 001 (Tuning)</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens, createTunedModel]</td>\n",
       "      <td>0.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>models/gemini-1.0-pro-vision-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro Vision</td>\n",
       "      <td>The best image understanding model to handle a...</td>\n",
       "      <td>12288</td>\n",
       "      <td>4096</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>models/gemini-pro-vision</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro Vision</td>\n",
       "      <td>The best image understanding model to handle a...</td>\n",
       "      <td>12288</td>\n",
       "      <td>4096</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>models/gemini-1.5-pro-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Pro Latest</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>2097152</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>models/gemini-1.5-pro-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Pro 001</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>2097152</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens, createCachedCon...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>models/gemini-1.5-pro</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Pro</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>2097152</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>models/gemini-1.5-flash-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Flash Latest</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>models/gemini-1.5-flash-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Flash 001</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens, createCachedCon...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>models/gemini-1.5-flash</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Flash</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>models/embedding-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Embedding 001</td>\n",
       "      <td>Obtain a distributed representation of a text.</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>[embedContent]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>models/text-embedding-004</td>\n",
       "      <td></td>\n",
       "      <td>004</td>\n",
       "      <td>Text Embedding 004</td>\n",
       "      <td>Obtain a distributed representation of a text.</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>[embedContent]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>models/aqa</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Model that performs Attributed Question Answer...</td>\n",
       "      <td>Model trained to return answers to questions t...</td>\n",
       "      <td>7168</td>\n",
       "      <td>1024</td>\n",
       "      <td>[generateAnswer]</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name base_model_id version  \\\n",
       "0                 models/chat-bison-001                   001   \n",
       "1                 models/text-bison-001                   001   \n",
       "2            models/embedding-gecko-001                   001   \n",
       "3          models/gemini-1.0-pro-latest                   001   \n",
       "4                 models/gemini-1.0-pro                   001   \n",
       "5                     models/gemini-pro                   001   \n",
       "6             models/gemini-1.0-pro-001                   001   \n",
       "7   models/gemini-1.0-pro-vision-latest                   001   \n",
       "8              models/gemini-pro-vision                   001   \n",
       "9          models/gemini-1.5-pro-latest                   001   \n",
       "10            models/gemini-1.5-pro-001                   001   \n",
       "11                models/gemini-1.5-pro                   001   \n",
       "12       models/gemini-1.5-flash-latest                   001   \n",
       "13          models/gemini-1.5-flash-001                   001   \n",
       "14              models/gemini-1.5-flash                   001   \n",
       "15                 models/embedding-001                   001   \n",
       "16            models/text-embedding-004                   004   \n",
       "17                           models/aqa                   001   \n",
       "\n",
       "                                         display_name  \\\n",
       "0                                PaLM 2 Chat (Legacy)   \n",
       "1                                     PaLM 2 (Legacy)   \n",
       "2                                     Embedding Gecko   \n",
       "3                               Gemini 1.0 Pro Latest   \n",
       "4                                      Gemini 1.0 Pro   \n",
       "5                                      Gemini 1.0 Pro   \n",
       "6                         Gemini 1.0 Pro 001 (Tuning)   \n",
       "7                               Gemini 1.0 Pro Vision   \n",
       "8                               Gemini 1.0 Pro Vision   \n",
       "9                               Gemini 1.5 Pro Latest   \n",
       "10                                 Gemini 1.5 Pro 001   \n",
       "11                                     Gemini 1.5 Pro   \n",
       "12                            Gemini 1.5 Flash Latest   \n",
       "13                               Gemini 1.5 Flash 001   \n",
       "14                                   Gemini 1.5 Flash   \n",
       "15                                      Embedding 001   \n",
       "16                                 Text Embedding 004   \n",
       "17  Model that performs Attributed Question Answer...   \n",
       "\n",
       "                                          description  input_token_limit  \\\n",
       "0   A legacy text-only model optimized for chat co...               4096   \n",
       "1   A legacy model that understands text and gener...               8196   \n",
       "2      Obtain a distributed representation of a text.               1024   \n",
       "3   The best model for scaling across a wide range...              30720   \n",
       "4   The best model for scaling across a wide range...              30720   \n",
       "5   The best model for scaling across a wide range...              30720   \n",
       "6   The best model for scaling across a wide range...              30720   \n",
       "7   The best image understanding model to handle a...              12288   \n",
       "8   The best image understanding model to handle a...              12288   \n",
       "9   Mid-size multimodal model that supports up to ...            2097152   \n",
       "10  Mid-size multimodal model that supports up to ...            2097152   \n",
       "11  Mid-size multimodal model that supports up to ...            2097152   \n",
       "12  Fast and versatile multimodal model for scalin...            1048576   \n",
       "13  Fast and versatile multimodal model for scalin...            1048576   \n",
       "14  Fast and versatile multimodal model for scalin...            1048576   \n",
       "15     Obtain a distributed representation of a text.               2048   \n",
       "16     Obtain a distributed representation of a text.               2048   \n",
       "17  Model trained to return answers to questions t...               7168   \n",
       "\n",
       "    output_token_limit                       supported_generation_methods  \\\n",
       "0                 1024              [generateMessage, countMessageTokens]   \n",
       "1                 1024  [generateText, countTextTokens, createTunedTex...   \n",
       "2                    1                       [embedText, countTextTokens]   \n",
       "3                 2048                     [generateContent, countTokens]   \n",
       "4                 2048                     [generateContent, countTokens]   \n",
       "5                 2048                     [generateContent, countTokens]   \n",
       "6                 2048   [generateContent, countTokens, createTunedModel]   \n",
       "7                 4096                     [generateContent, countTokens]   \n",
       "8                 4096                     [generateContent, countTokens]   \n",
       "9                 8192                     [generateContent, countTokens]   \n",
       "10                8192  [generateContent, countTokens, createCachedCon...   \n",
       "11                8192                     [generateContent, countTokens]   \n",
       "12                8192                     [generateContent, countTokens]   \n",
       "13                8192  [generateContent, countTokens, createCachedCon...   \n",
       "14                8192                     [generateContent, countTokens]   \n",
       "15                   1                                     [embedContent]   \n",
       "16                   1                                     [embedContent]   \n",
       "17                1024                                   [generateAnswer]   \n",
       "\n",
       "    temperature  max_temperature  top_p  top_k  \n",
       "0          0.25              NaN   0.95   40.0  \n",
       "1          0.70              NaN   0.95   40.0  \n",
       "2           NaN              NaN    NaN    NaN  \n",
       "3          0.90              NaN   1.00    NaN  \n",
       "4          0.90              NaN   1.00    NaN  \n",
       "5          0.90              NaN   1.00    NaN  \n",
       "6          0.90              NaN   1.00    NaN  \n",
       "7          0.40              NaN   1.00   32.0  \n",
       "8          0.40              NaN   1.00   32.0  \n",
       "9          1.00              2.0   0.95   64.0  \n",
       "10         1.00              2.0   0.95   64.0  \n",
       "11         1.00              2.0   0.95   64.0  \n",
       "12         1.00              2.0   0.95   64.0  \n",
       "13         1.00              2.0   0.95   64.0  \n",
       "14         1.00              2.0   0.95   64.0  \n",
       "15          NaN              NaN    NaN    NaN  \n",
       "16          NaN              NaN    NaN    NaN  \n",
       "17         0.20              NaN   1.00   40.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58d2c8-401a-4678-adad-a891ed703866",
   "metadata": {},
   "source": [
    "#### Legacy models are no longer accessible.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ab5312a-ce76-4687-ade4-0002ec6099a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro\n",
      "models/gemini-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    if \"generateContent\" in model.supported_generation_methods:\n",
    "        print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e12acae-8aae-4bd1-86fa-fa7abecfb01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>base_model_id</th>\n",
       "      <th>version</th>\n",
       "      <th>display_name</th>\n",
       "      <th>description</th>\n",
       "      <th>input_token_limit</th>\n",
       "      <th>output_token_limit</th>\n",
       "      <th>supported_generation_methods</th>\n",
       "      <th>temperature</th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>top_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>models/gemini-1.0-pro-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro Latest</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>models/gemini-1.0-pro</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>models/gemini-pro</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>models/gemini-1.0-pro-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro 001 (Tuning)</td>\n",
       "      <td>The best model for scaling across a wide range...</td>\n",
       "      <td>30720</td>\n",
       "      <td>2048</td>\n",
       "      <td>[generateContent, countTokens, createTunedModel]</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>models/gemini-1.0-pro-vision-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro Vision</td>\n",
       "      <td>The best image understanding model to handle a...</td>\n",
       "      <td>12288</td>\n",
       "      <td>4096</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>models/gemini-pro-vision</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.0 Pro Vision</td>\n",
       "      <td>The best image understanding model to handle a...</td>\n",
       "      <td>12288</td>\n",
       "      <td>4096</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>models/gemini-1.5-pro-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Pro Latest</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>2097152</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>models/gemini-1.5-pro-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Pro 001</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>2097152</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens, createCachedCon...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>models/gemini-1.5-pro</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Pro</td>\n",
       "      <td>Mid-size multimodal model that supports up to ...</td>\n",
       "      <td>2097152</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>models/gemini-1.5-flash-latest</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Flash Latest</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>models/gemini-1.5-flash-001</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Flash 001</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens, createCachedCon...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>models/gemini-1.5-flash</td>\n",
       "      <td></td>\n",
       "      <td>001</td>\n",
       "      <td>Gemini 1.5 Flash</td>\n",
       "      <td>Fast and versatile multimodal model for scalin...</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8192</td>\n",
       "      <td>[generateContent, countTokens]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name base_model_id version  \\\n",
       "0          models/gemini-1.0-pro-latest                   001   \n",
       "1                 models/gemini-1.0-pro                   001   \n",
       "2                     models/gemini-pro                   001   \n",
       "3             models/gemini-1.0-pro-001                   001   \n",
       "4   models/gemini-1.0-pro-vision-latest                   001   \n",
       "5              models/gemini-pro-vision                   001   \n",
       "6          models/gemini-1.5-pro-latest                   001   \n",
       "7             models/gemini-1.5-pro-001                   001   \n",
       "8                 models/gemini-1.5-pro                   001   \n",
       "9        models/gemini-1.5-flash-latest                   001   \n",
       "10          models/gemini-1.5-flash-001                   001   \n",
       "11              models/gemini-1.5-flash                   001   \n",
       "\n",
       "                   display_name  \\\n",
       "0         Gemini 1.0 Pro Latest   \n",
       "1                Gemini 1.0 Pro   \n",
       "2                Gemini 1.0 Pro   \n",
       "3   Gemini 1.0 Pro 001 (Tuning)   \n",
       "4         Gemini 1.0 Pro Vision   \n",
       "5         Gemini 1.0 Pro Vision   \n",
       "6         Gemini 1.5 Pro Latest   \n",
       "7            Gemini 1.5 Pro 001   \n",
       "8                Gemini 1.5 Pro   \n",
       "9       Gemini 1.5 Flash Latest   \n",
       "10         Gemini 1.5 Flash 001   \n",
       "11             Gemini 1.5 Flash   \n",
       "\n",
       "                                          description  input_token_limit  \\\n",
       "0   The best model for scaling across a wide range...              30720   \n",
       "1   The best model for scaling across a wide range...              30720   \n",
       "2   The best model for scaling across a wide range...              30720   \n",
       "3   The best model for scaling across a wide range...              30720   \n",
       "4   The best image understanding model to handle a...              12288   \n",
       "5   The best image understanding model to handle a...              12288   \n",
       "6   Mid-size multimodal model that supports up to ...            2097152   \n",
       "7   Mid-size multimodal model that supports up to ...            2097152   \n",
       "8   Mid-size multimodal model that supports up to ...            2097152   \n",
       "9   Fast and versatile multimodal model for scalin...            1048576   \n",
       "10  Fast and versatile multimodal model for scalin...            1048576   \n",
       "11  Fast and versatile multimodal model for scalin...            1048576   \n",
       "\n",
       "    output_token_limit                       supported_generation_methods  \\\n",
       "0                 2048                     [generateContent, countTokens]   \n",
       "1                 2048                     [generateContent, countTokens]   \n",
       "2                 2048                     [generateContent, countTokens]   \n",
       "3                 2048   [generateContent, countTokens, createTunedModel]   \n",
       "4                 4096                     [generateContent, countTokens]   \n",
       "5                 4096                     [generateContent, countTokens]   \n",
       "6                 8192                     [generateContent, countTokens]   \n",
       "7                 8192  [generateContent, countTokens, createCachedCon...   \n",
       "8                 8192                     [generateContent, countTokens]   \n",
       "9                 8192                     [generateContent, countTokens]   \n",
       "10                8192  [generateContent, countTokens, createCachedCon...   \n",
       "11                8192                     [generateContent, countTokens]   \n",
       "\n",
       "    temperature  max_temperature  top_p  top_k  \n",
       "0           0.9              NaN   1.00    NaN  \n",
       "1           0.9              NaN   1.00    NaN  \n",
       "2           0.9              NaN   1.00    NaN  \n",
       "3           0.9              NaN   1.00    NaN  \n",
       "4           0.4              NaN   1.00   32.0  \n",
       "5           0.4              NaN   1.00   32.0  \n",
       "6           1.0              2.0   0.95   64.0  \n",
       "7           1.0              2.0   0.95   64.0  \n",
       "8           1.0              2.0   0.95   64.0  \n",
       "9           1.0              2.0   0.95   64.0  \n",
       "10          1.0              2.0   0.95   64.0  \n",
       "11          1.0              2.0   0.95   64.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accessible_model = list()\n",
    "for model in genai.list_models():\n",
    "    if \"generateContent\" in model.supported_generation_methods:\n",
    "        accessible_model.append(model)\n",
    "pd.DataFrame(accessible_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09bb34-7f12-464a-b530-440b7da3064d",
   "metadata": {},
   "source": [
    "#### Above 11 models are accessible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081411ef-0b19-4ef8-8232-3b763137ceef",
   "metadata": {},
   "source": [
    "## 4) Text-2-Text Generation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37cb3d11-cf60-4d02-ae91-5666bcfc4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing Model\n",
    "model = genai.GenerativeModel(\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3581267-8e58-45c3-ad04-76131c014c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 8.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = model.generate_content(\"What is meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "955ad4dd-96d6-4b06-a125-08523b8f026d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"The meaning of life is a deeply personal and subjective question that has been pondered by philosophers, theologians, and scientists for centuries. There is no one definitive answer, but rather a wide range of perspectives on what constitutes a meaningful life. Some common themes that emerge include:\\n\\n**Purpose and Fulfillment:** Many people find meaning in pursuing activities that align with their values and passions. This may involve making a contribution to society, creating something meaningful, or experiencing personal growth and fulfillment.\\n\\n**Relationships and Connections:** Strong social connections with family, friends, and loved ones can provide a sense of purpose and belonging. Building meaningful relationships can contribute to an overall feeling of well-being and satisfaction.\\n\\n**Personal Growth and Development:** Engaging in self-reflection and seeking opportunities for learning and growth can help individuals discover their potential and live a more fulfilling life. Personal development may involve setting goals, overcoming challenges, and embracing new experiences.\\n\\n**Contribution to Society:** Some people find meaning in contributing to the well-being of others or making a positive impact on their community or the world at large. This may involve volunteering, participating in social or political movements, or simply showing kindness and compassion to those around them.\\n\\n**Experiencing the Present Moment:** Mindfulness and the ability to appreciate the present moment can bring a sense of tranquility and gratitude. Paying attention to the small things and savoring experiences can help individuals appreciate the beauty and meaning in everyday life.\\n\\n**Spiritual or Religious Beliefs:** For some, religion or spirituality provides a framework for understanding the meaning of life and the purpose of their existence. Religious teachings and practices can offer guidance, comfort, and a sense of connection to a higher power.\\n\\nUltimately, the meaning of life is unique to each individual and can evolve over time. It is a personal journey of exploration, self-discovery, and the pursuit of what brings fulfillment and purpose.\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 7,\n",
       "        \"candidates_token_count\": 376,\n",
       "        \"total_token_count\": 383\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n",
    "# \"usage_metadata\": {\n",
    "#   \"prompt_token_count\": 7,   -> in openai tokenizer if u paste input/prompt then u get 6 tokens 24 characters....in google tokenizer it is 7\n",
    "#   \"candidates_token_count\": 376, -> in openai 395 tokens,,,,,,,,,,in google tokenizer it is 376\n",
    "#   \"total_token_count\": 383\n",
    "# }\n",
    "#ie: each tokenizer model works differently,,,,,,,,,,,,,,,,openai tokenizer works differently,googles tokenizer/embedding works differently\n",
    "#tokenizer means -> breaking down textinto tokens\n",
    "#embeddings means -> converting each token of text is converted  to vector,,,and finally aggregating these vectors to single vector.\n",
    "#ie;if text has 5 words in it thus we get 5 vectors and finally aggregating these 5 vectors to get single vector which represent this text..aggregating means(average of 5 vectors or sum of 5 vectors...etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9385c-c0c9-41bb-bd74-4c496138aea3",
   "metadata": {},
   "source": [
    "- **check metric for tokens usage**\n",
    "- https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/metrics?project=gen-lang-client-0034393728 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b7ff8bb-3564-4025-bda3-696f13525d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The meaning of life is a deeply personal and subjective question that has been pondered by philosophers, theologians, and scientists for centuries. There is no one definitive answer, but rather a wide range of perspectives on what constitutes a meaningful life. Some common themes that emerge include:\\n\\n**Purpose and Fulfillment:** Many people find meaning in pursuing activities that align with their values and passions. This may involve making a contribution to society, creating something meaningful, or experiencing personal growth and fulfillment.\\n\\n**Relationships and Connections:** Strong social connections with family, friends, and loved ones can provide a sense of purpose and belonging. Building meaningful relationships can contribute to an overall feeling of well-being and satisfaction.\\n\\n**Personal Growth and Development:** Engaging in self-reflection and seeking opportunities for learning and growth can help individuals discover their potential and live a more fulfilling life. Personal development may involve setting goals, overcoming challenges, and embracing new experiences.\\n\\n**Contribution to Society:** Some people find meaning in contributing to the well-being of others or making a positive impact on their community or the world at large. This may involve volunteering, participating in social or political movements, or simply showing kindness and compassion to those around them.\\n\\n**Experiencing the Present Moment:** Mindfulness and the ability to appreciate the present moment can bring a sense of tranquility and gratitude. Paying attention to the small things and savoring experiences can help individuals appreciate the beauty and meaning in everyday life.\\n\\n**Spiritual or Religious Beliefs:** For some, religion or spirituality provides a framework for understanding the meaning of life and the purpose of their existence. Religious teachings and practices can offer guidance, comfort, and a sense of connection to a higher power.\\n\\nUltimately, the meaning of life is unique to each individual and can evolve over time. It is a personal journey of exploration, self-discovery, and the pursuit of what brings fulfillment and purpose.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b632cac-6794-4bfd-8914-67581cf333ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> The meaning of life is a deeply personal and subjective question that has been pondered by philosophers, theologians, and scientists for centuries. There is no one definitive answer, but rather a wide range of perspectives on what constitutes a meaningful life. Some common themes that emerge include:\n",
       "> \n",
       "> **Purpose and Fulfillment:** Many people find meaning in pursuing activities that align with their values and passions. This may involve making a contribution to society, creating something meaningful, or experiencing personal growth and fulfillment.\n",
       "> \n",
       "> **Relationships and Connections:** Strong social connections with family, friends, and loved ones can provide a sense of purpose and belonging. Building meaningful relationships can contribute to an overall feeling of well-being and satisfaction.\n",
       "> \n",
       "> **Personal Growth and Development:** Engaging in self-reflection and seeking opportunities for learning and growth can help individuals discover their potential and live a more fulfilling life. Personal development may involve setting goals, overcoming challenges, and embracing new experiences.\n",
       "> \n",
       "> **Contribution to Society:** Some people find meaning in contributing to the well-being of others or making a positive impact on their community or the world at large. This may involve volunteering, participating in social or political movements, or simply showing kindness and compassion to those around them.\n",
       "> \n",
       "> **Experiencing the Present Moment:** Mindfulness and the ability to appreciate the present moment can bring a sense of tranquility and gratitude. Paying attention to the small things and savoring experiences can help individuals appreciate the beauty and meaning in everyday life.\n",
       "> \n",
       "> **Spiritual or Religious Beliefs:** For some, religion or spirituality provides a framework for understanding the meaning of life and the purpose of their existence. Religious teachings and practices can offer guidance, comfort, and a sense of connection to a higher power.\n",
       "> \n",
       "> Ultimately, the meaning of life is unique to each individual and can evolve over time. It is a personal journey of exploration, self-discovery, and the pursuit of what brings fulfillment and purpose."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)\n",
    "#formatting response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fab2113-1d26-411b-a1b1-99017f7e9bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[index: 0\n",
       "content {\n",
       "  parts {\n",
       "    text: \"The meaning of life is a deeply personal and subjective question that has been pondered by philosophers, theologians, and scientists for centuries. There is no one definitive answer, but rather a wide range of perspectives on what constitutes a meaningful life. Some common themes that emerge include:\\n\\n**Purpose and Fulfillment:** Many people find meaning in pursuing activities that align with their values and passions. This may involve making a contribution to society, creating something meaningful, or experiencing personal growth and fulfillment.\\n\\n**Relationships and Connections:** Strong social connections with family, friends, and loved ones can provide a sense of purpose and belonging. Building meaningful relationships can contribute to an overall feeling of well-being and satisfaction.\\n\\n**Personal Growth and Development:** Engaging in self-reflection and seeking opportunities for learning and growth can help individuals discover their potential and live a more fulfilling life. Personal development may involve setting goals, overcoming challenges, and embracing new experiences.\\n\\n**Contribution to Society:** Some people find meaning in contributing to the well-being of others or making a positive impact on their community or the world at large. This may involve volunteering, participating in social or political movements, or simply showing kindness and compassion to those around them.\\n\\n**Experiencing the Present Moment:** Mindfulness and the ability to appreciate the present moment can bring a sense of tranquility and gratitude. Paying attention to the small things and savoring experiences can help individuals appreciate the beauty and meaning in everyday life.\\n\\n**Spiritual or Religious Beliefs:** For some, religion or spirituality provides a framework for understanding the meaning of life and the purpose of their existence. Religious teachings and practices can offer guidance, comfort, and a sense of connection to a higher power.\\n\\nUltimately, the meaning of life is unique to each individual and can evolve over time. It is a personal journey of exploration, self-discovery, and the pursuit of what brings fulfillment and purpose.\"\n",
       "  }\n",
       "  role: \"model\"\n",
       "}\n",
       "finish_reason: STOP\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HATE_SPEECH\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_HARASSMENT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "safety_ratings {\n",
       "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "  probability: NEGLIGIBLE\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates\n",
    "#if u mentioned give me multiple possible answer,,then model will return you multiple answer,,and at the top,,best answer is present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded77a8-96c0-47e4-9eb8-c6e707bfb5d5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "- One thing,,you know,,when you give prompt to chatgpt , gemini,,then it will not produce answer at one go,,,,instead it will produce line by , left to right , top to bottom manner,,and this is called streaming of answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdb4d844-f9fb-45ff-9704-7ba590c52a63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 2.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=False,\n",
       "    iterator=<_StreamingResponseIterator>,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"The meaning of life is a deep philosophical question that has been pondered by humans for\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 7,\n",
       "        \"candidates_token_count\": 16,\n",
       "        \"total_token_count\": 23\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "response = model.generate_content(\"What is meaning of life?\" , stream=True)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cfc5bdc-019e-498f-995d-300b1f0d8389",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The meaning of life is a deep philosophical question that has been pondered by humans for\n",
      "________________________________________________________________________________________________________________________\n",
      "1  centuries. There is no one definitive answer, as the meaning of life is a personal and subjective experience that varies from individual to individual. However, some common themes\n",
      "________________________________________________________________________________________________________________________\n",
      "2  that emerge when people contemplate the meaning of life include:\n",
      "\n",
      "* **Purpose:** Feeling a sense of purpose and direction in life can give us a sense of meaning. This could come from our work, hobbies, relationships, or any other activity that we find fulfilling.\n",
      "* **Values:** Our values define what is important\n",
      "________________________________________________________________________________________________________________________\n",
      "3  to us and help us to make choices about how we live our lives. When we live in accordance with our values, we feel a sense of alignment and purpose.\n",
      "* **Relationships:** Strong and meaningful relationships can give us a sense of belonging and connection to others. Sharing our lives with loved ones can help us to feel supported and fulfilled.\n",
      "* **Contribution:** Feeling like we are making a positive contribution to the world can give us a sense of meaning. This could involve volunteering, helping others, or creating something that benefits society.\n",
      "* **Growth and learning:** Continuously learning and growing throughout our lives can help us to feel\n",
      "________________________________________________________________________________________________________________________\n",
      "4  a sense of purpose and fulfillment. This could involve taking classes, reading books, or simply exploring new experiences.\n",
      "\n",
      "Ultimately, the meaning of life is something that each individual must discover for themselves. There is no right or wrong answer, and it is a journey that can evolve and change over time.\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i , chunk in enumerate(response):\n",
    "    print(i,chunk.text)\n",
    "    print(\"__\"*60)\n",
    "\n",
    "#1st ,, 0th text is generated,,then 1th , then 2th...like this,,one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b2430-cdb5-4bd8-ad08-f0e1f0b7f943",
   "metadata": {},
   "source": [
    "## 5) Image-2-Text Generation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00bae8f4-8c2b-4cc8-89fe-bd5c2db2016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b223f816-332a-4469-ad46-f1ee498e763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_img = IPImage(filename=\"image.jpeg\")\n",
    "#Using the IPython.display.Image object, ip_img, you are preparing the image in a format that should be compatible with the generate_content \n",
    "#method from the Google Generative AI library.\n",
    "#Making jpeg compatible with generate_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "985db539-2d05-4e9b-89e5-7a660dc1c4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "745c2957-8f1e-4dd9-8b79-408f9770d149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'IPython.core.display.Image'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ip_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23686d95-d581-4945-87f1-d9a6a63e2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "#pro-vision is legacy or depricated,,so use flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "089ebce8-bb9b-4e76-8a52-3ed1462410e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model2.generate_content(ip_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9611a450-8188-4921-96bf-4d02ee2d8bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> This is a depiction of Shiva, a major deity in Hinduism. He is often associated with destruction and transformation, but also with yogic practices and the cycle of life and death. \n",
       "> \n",
       "> Here are some key elements of this image:\n",
       "> \n",
       "> * **The Trishula:** The three-pronged spear is Shiva's primary weapon and symbol of his power to destroy illusions and negativity. \n",
       "> * **The Damaru:** The small drum held in Shiva's left hand represents the rhythm of creation and the sounds of the cosmos. \n",
       "> * **The Snake:** The cobra wrapped around Shiva's neck, symbolizes his control over the destructive forces of nature and the cycles of life and death.\n",
       "> * **The Ascetic Appearance:** Shiva's ash-smeared body and matted hair represent his detachment from worldly desires and his focus on spiritual pursuit.\n",
       "> * **The Mountains and Ice:** The snowy mountain backdrop suggests Shiva's association with the Himalayas, a place of great spiritual power. \n",
       "> \n",
       "> It's important to remember that the representation of deities in Hinduism can vary across different traditions and interpretations.  This is just one depiction of Shiva. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde7c6e-13ad-4883-93f9-2f71a9227b73",
   "metadata": {},
   "source": [
    "#### Passing text and image together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c1ff3cd-3ce6-4770-ba27-40274dbf4af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = model2.generate_content([ \"Which god's pic it is?\" , ip_img])\n",
    "#response = model2.generate_content([ \"Which god's pic it is?\" , ip_img1 , ip_img2 , ip_img3,........ip_imgN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "160ea6a7-1e4d-442d-a2dc-2d8b40fcf796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> This is a picture of **Lord Shiva**, one of the most important deities in Hinduism. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be304e14-7601-41ef-ae4b-d45f2eda6d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
