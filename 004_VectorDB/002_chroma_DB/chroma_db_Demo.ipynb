{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43b48399-cdc7-4bc2-9e8b-f509d7fc32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4262a14e-e54a-464b-91da-56a5bc3a05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e99948-a3b7-4530-96ad-21bd911e6c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: chromadb\n",
      "Version: 0.5.5\n",
      "Summary: Chroma.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
      "License: \n",
      "Location: C:\\Users\\shree\\.conda\\envs\\playing_with_genai\\Lib\\site-packages\n",
      "Requires: bcrypt, build, chroma-hnswlib, fastapi, grpcio, httpx, importlib-resources, kubernetes, mmh3, numpy, onnxruntime, opentelemetry-api, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, opentelemetry-sdk, orjson, overrides, posthog, pydantic, pypika, PyYAML, tenacity, tokenizers, tqdm, typer, typing-extensions, uvicorn\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a535ed-58a1-467f-ae3d-14cdb935eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c6a78-5770-4ddd-a8f7-4bbc56d66925",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "#Set api key in environmental variable,,thus while calling model ,, intrnally referred...........OPENAI_API_KEY is special/predefined meaning,,dont change name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87c0ea2-2149-44d9-b4fa-f52754bc14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings #Although i am using Word2Vec pretrained model instead openai's embedding model,,u can use any other pretrained embedding model like BERT,GPT..etc,,,,just to practice..LOL\n",
    "from langchain.llms import OpenAI #not going to use it,,bcz not have money,,,just written for practice\n",
    "from langchain.document_loaders import DirectoryLoader , TextLoader #DirectoryLoader -> mention path for directory,,and it will read all files from it , TextLoader -> mention ,txt file path and it will load that file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc22b6a-07d8-4e51-a113-178c33370524",
   "metadata": {},
   "source": [
    "## 1) Load The Documents (.txt, .pdf , .csv ,....etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d548013-b850-40f8-b180-21eb4640bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"Resume_Data\" , glob=\"./*.txt\" , loader_cls=TextLoader)\n",
    "#Read all .txt files from specified directory,,,this directory has pdf , txt , word(.docx) and csv files,,,,but our code considered just txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48091ba-b9fa-4f8a-858a-4dd3f4cd9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0405f6e2-d4dc-45fb-9788-9f995d71bcdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content='####NOTE-> There is no recharge kind of things,as u do for mobile recharge like 299 for 1 month,,,,,,,,,,,,,,,,,,,,,,,,,\\n##in openai this kind of thing is not there,,where you have to to pay x amount and you will get y tokens........no\\n#just give credit card details -> use any models you want ->  open ai will track , which model you are using,whats is the tokens rate for it..etc -> and after completeting billing cycle(generally 1 month is there) tou get invoice and payment is deducted from your card,,,-> if card has not enough money,,then you are temporarily suspened,,untill you pay there charges ,,,untill that you are not able to use there model.......\\n\\n##############################################################################################################\\n1st) you have to add debit card details(ecommerce and international transaction should be enabled ie;VISA )\\n2nd) you can add $5 to $100 in your openai account,,,,,,,,,,after billing cycle or 1 month amount is deducted from it,,w.r.t usage of tokens in total\\n3rd) you can add threshold,,,when your openai amount is lesser than this then automatically money is debitted from your account,,,,,,,,,,,,,,,ie;you have to provide minimum and maximum amount should present in you account as threshold\\n\\nBilling Process Overview\\nCredit Card Setup\\n\\nEntry: Provide your credit card details in OpenAIâ€™s billing settings.\\nVerification: OpenAI verifies the card for payment processing.\\nUsage Tracking\\n\\nAPI Requests: OpenAI tracks your usage of API models based on the number of tokens processed or requests made.\\nModel-Specific Pricing: Each model has its own token pricing (e.g., GPT-4o Mini).\\nBilling Cycle\\n\\nCycle Duration: Typically monthly. Usage is tracked continuously throughout this period.\\nAggregation: At the end of the cycle, total usage is aggregated.\\nCharges and Payment\\n\\nInvoice Generation: An invoice is generated detailing your usage and charges.\\nAutomatic Deduction: The total amount due is automatically deducted from your credit card. This usually happens at the end of the billing cycle or shortly thereafter.\\nNo Per-Request Charges: You are not charged after each individual API request; charges accumulate over the billing cycle.\\nHandling Payment Issues\\n\\nFailed Payments: If thereâ€™s an issue (e.g., insufficient funds), OpenAI will notify you and may suspend or limit your access until resolved.\\nResolution: Update your payment details or resolve the issue as needed.\\nModel-Specific Pricing Example\\n\\nGPT-4o Mini Pricing:\\nInput Tokens: $0.000150 per 1,000 tokens\\nOutput Tokens: $0.000600 per 1,000 tokens\\nExample Calculation: For 10,000 input tokens and 5,000 output tokens, the total cost would be $0.0045.\\nMonitoring and Management\\n\\nDashboard: Use OpenAIâ€™s dashboard to monitor usage and manage billing settings.\\nSupport: Contact support for any billing issues or discrepancies.\\nKey Points\\nMonthly Billing: Usage is tracked monthly, and charges are applied at the end of the billing cycle.\\nModel Pricing: Charges depend on the model used and its specific token rates.\\nAutomatic Payment: Your credit card is automatically charged based on aggregated usage.\\nThis process helps in managing and understanding your API costs effectively while ensuring seamless access to OpenAIâ€™s services.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_data \n",
    "#When you read data using pypdf,document loader ..etc class,,then it will give you list like below\n",
    "#[Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content=.......] 1 document..............same conventions is used whenever you read the data using pypdf,document loader..\n",
    "#each page data is represented in page_content variable......\n",
    "\n",
    "#when you do chunking,,then also same convention is used to represent each chunk ... ie; data is present in page_content....ie;in this format/convention only -> [Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content=.............\n",
    "#Thus all langchain method will take this raw document,,and internally access page_content,so not need to manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ab7c22-7b05-4268-bf3d-63b45c4f17b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'####NOTE-> There is no recharge kind of things,as u do for mobile recharge like 299 for 1 month,,,,,,,,,,,,,,,,,,,,,,,,,\\n##in openai this kind of thing is not there,,where you have to to pay x amount and you will get y tokens........no\\n#just give credit card details -> use any models you want ->  open ai will track , which model you are using,whats is the tokens rate for it..etc -> and after completeting billing cycle(generally 1 month is there) tou get invoice and payment is deducted from your card,,,-> if card has not enough money,,then you are temporarily suspened,,untill you pay there charges ,,,untill that you are not able to use there model.......\\n\\n##############################################################################################################\\n1st) you have to add debit card details(ecommerce and international transaction should be enabled ie;VISA )\\n2nd) you can add $5 to $100 in your openai account,,,,,,,,,,after billing cycle or 1 month amount is deducted from it,,w.r.t usage of tokens in total\\n3rd) you can add threshold,,,when your openai amount is lesser than this then automatically money is debitted from your account,,,,,,,,,,,,,,,ie;you have to provide minimum and maximum amount should present in you account as threshold\\n\\nBilling Process Overview\\nCredit Card Setup\\n\\nEntry: Provide your credit card details in OpenAIâ€™s billing settings.\\nVerification: OpenAI verifies the card for payment processing.\\nUsage Tracking\\n\\nAPI Requests: OpenAI tracks your usage of API models based on the number of tokens processed or requests made.\\nModel-Specific Pricing: Each model has its own token pricing (e.g., GPT-4o Mini).\\nBilling Cycle\\n\\nCycle Duration: Typically monthly. Usage is tracked continuously throughout this period.\\nAggregation: At the end of the cycle, total usage is aggregated.\\nCharges and Payment\\n\\nInvoice Generation: An invoice is generated detailing your usage and charges.\\nAutomatic Deduction: The total amount due is automatically deducted from your credit card. This usually happens at the end of the billing cycle or shortly thereafter.\\nNo Per-Request Charges: You are not charged after each individual API request; charges accumulate over the billing cycle.\\nHandling Payment Issues\\n\\nFailed Payments: If thereâ€™s an issue (e.g., insufficient funds), OpenAI will notify you and may suspend or limit your access until resolved.\\nResolution: Update your payment details or resolve the issue as needed.\\nModel-Specific Pricing Example\\n\\nGPT-4o Mini Pricing:\\nInput Tokens: $0.000150 per 1,000 tokens\\nOutput Tokens: $0.000600 per 1,000 tokens\\nExample Calculation: For 10,000 input tokens and 5,000 output tokens, the total cost would be $0.0045.\\nMonitoring and Management\\n\\nDashboard: Use OpenAIâ€™s dashboard to monitor usage and manage billing settings.\\nSupport: Contact support for any billing issues or discrepancies.\\nKey Points\\nMonthly Billing: Usage is tracked monthly, and charges are applied at the end of the billing cycle.\\nModel Pricing: Charges depend on the model used and its specific token rates.\\nAutomatic Payment: Your credit card is automatically charged based on aggregated usage.\\nThis process helps in managing and understanding your API costs effectively while ensuring seamless access to OpenAIâ€™s services.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d282ca1a-b6c1-441f-91b5-58d7db4d2f14",
   "metadata": {},
   "source": [
    "## 2) breakdown above data into sentences or paragraphs or chunks,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8796c953-6bd7-46fb-87fd-17f9b6b9220e",
   "metadata": {},
   "source": [
    "- bcz many models process 4096 tokens or words at a time like gpt 3.5 turbo...etc or per minute it can process x amount of tokens only,,,,,in that caseif u give any data which has more tokens than it can process at a time then it will not process it,,,so for that case we have to pass input in chunk\n",
    "- **if data is very-very huge,,then you cant pass this data directly to any Gen AI model (llm/lim/mm and Embedding model),,,we have to do chunking and pass it**\n",
    "- bcz every gen ai model and embedding model has some limitation over token processing,,,,,so this technique will help in those case\n",
    "- **1 document means 1 sentence, documents means set or collection of sentence**,,,see \"document_list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd7348d-a5e0-4d02-aab6-85efa4afeab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9733f3af-0286-462d-96a1-bd88467cc3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000 , chunk_overlap=20)\n",
    "#each chunk or sentence or paragraph has on an average 1000 tokens or words in it............not exactlt 1000 tokencan come in chunk\n",
    "#last 20 tokens or word of i th chunk is starting of i+1 th chunk,,,,,,,,,,,,,,,,,,,,for i=1,,there is no previous chunk so,,no repeataion\n",
    "#ie;last 20 tokens or word of i th chunk is carried to i+1 th chunk\n",
    "#and also , we use chunk_overlap to sustain context or info of previous chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7280383e-e2a2-4168-bcfa-ffad69c42ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_splitter.split_documents(fetched_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "082d2c7a-0f62-4135-956b-deefa82fb2c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content='####NOTE-> There is no recharge kind of things,as u do for mobile recharge like 299 for 1 month,,,,,,,,,,,,,,,,,,,,,,,,,\\n##in openai this kind of thing is not there,,where you have to to pay x amount and you will get y tokens........no\\n#just give credit card details -> use any models you want ->  open ai will track , which model you are using,whats is the tokens rate for it..etc -> and after completeting billing cycle(generally 1 month is there) tou get invoice and payment is deducted from your card,,,-> if card has not enough money,,then you are temporarily suspened,,untill you pay there charges ,,,untill that you are not able to use there model.......'),\n",
       " Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content='##############################################################################################################\\n1st) you have to add debit card details(ecommerce and international transaction should be enabled ie;VISA )\\n2nd) you can add $5 to $100 in your openai account,,,,,,,,,,after billing cycle or 1 month amount is deducted from it,,w.r.t usage of tokens in total\\n3rd) you can add threshold,,,when your openai amount is lesser than this then automatically money is debitted from your account,,,,,,,,,,,,,,,ie;you have to provide minimum and maximum amount should present in you account as threshold\\n\\nBilling Process Overview\\nCredit Card Setup\\n\\nEntry: Provide your credit card details in OpenAIâ€™s billing settings.\\nVerification: OpenAI verifies the card for payment processing.\\nUsage Tracking'),\n",
       " Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content='API Requests: OpenAI tracks your usage of API models based on the number of tokens processed or requests made.\\nModel-Specific Pricing: Each model has its own token pricing (e.g., GPT-4o Mini).\\nBilling Cycle\\n\\nCycle Duration: Typically monthly. Usage is tracked continuously throughout this period.\\nAggregation: At the end of the cycle, total usage is aggregated.\\nCharges and Payment\\n\\nInvoice Generation: An invoice is generated detailing your usage and charges.\\nAutomatic Deduction: The total amount due is automatically deducted from your credit card. This usually happens at the end of the billing cycle or shortly thereafter.\\nNo Per-Request Charges: You are not charged after each individual API request; charges accumulate over the billing cycle.\\nHandling Payment Issues'),\n",
       " Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content='Failed Payments: If thereâ€™s an issue (e.g., insufficient funds), OpenAI will notify you and may suspend or limit your access until resolved.\\nResolution: Update your payment details or resolve the issue as needed.\\nModel-Specific Pricing Example\\n\\nGPT-4o Mini Pricing:\\nInput Tokens: $0.000150 per 1,000 tokens\\nOutput Tokens: $0.000600 per 1,000 tokens\\nExample Calculation: For 10,000 input tokens and 5,000 output tokens, the total cost would be $0.0045.\\nMonitoring and Management'),\n",
       " Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content='Dashboard: Use OpenAIâ€™s dashboard to monitor usage and manage billing settings.\\nSupport: Contact support for any billing issues or discrepancies.\\nKey Points\\nMonthly Billing: Usage is tracked monthly, and charges are applied at the end of the billing cycle.\\nModel Pricing: Charges depend on the model used and its specific token rates.\\nAutomatic Payment: Your credit card is automatically charged based on aggregated usage.\\nThis process helps in managing and understanding your API costs effectively while ensuring seamless access to OpenAIâ€™s services.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text\n",
    "#each sentence/chunk is represented as 1 document ....\n",
    "#[Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content=.........] -> 1 document or 1 sentence or 1 chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18205b13-5abc-40f6-b8d3-99a9642185fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##############################################################################################################\\n1st) you have to add debit card details(ecommerce and international transaction should be enabled ie;VISA )\\n2nd) you can add $5 to $100 in your openai account,,,,,,,,,,after billing cycle or 1 month amount is deducted from it,,w.r.t usage of tokens in total\\n3rd) you can add threshold,,,when your openai amount is lesser than this then automatically money is debitted from your account,,,,,,,,,,,,,,,ie;you have to provide minimum and maximum amount should present in you account as threshold\\n\\nBilling Process Overview\\nCredit Card Setup\\n\\nEntry: Provide your credit card details in OpenAIâ€™s billing settings.\\nVerification: OpenAI verifies the card for payment processing.\\nUsage Tracking'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08a5ada1-6b3c-4cd9-87d3-78521e0555d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)\n",
    "#5 chunks are formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef02d06-9656-4112-bc5d-4d20b591bb04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['####NOTE-> There is no recharge kind of things,as u do for mobile recharge like 299 for 1 month,,,,,,,,,,,,,,,,,,,,,,,,,\\n##in openai this kind of thing is not there,,where you have to to pay x amount and you will get y tokens........no\\n#just give credit card details -> use any models you want ->  open ai will track , which model you are using,whats is the tokens rate for it..etc -> and after completeting billing cycle(generally 1 month is there) tou get invoice and payment is deducted from your card,,,-> if card has not enough money,,then you are temporarily suspened,,untill you pay there charges ,,,untill that you are not able to use there model.......',\n",
       " '##############################################################################################################\\n1st) you have to add debit card details(ecommerce and international transaction should be enabled ie;VISA )\\n2nd) you can add $5 to $100 in your openai account,,,,,,,,,,after billing cycle or 1 month amount is deducted from it,,w.r.t usage of tokens in total\\n3rd) you can add threshold,,,when your openai amount is lesser than this then automatically money is debitted from your account,,,,,,,,,,,,,,,ie;you have to provide minimum and maximum amount should present in you account as threshold\\n\\nBilling Process Overview\\nCredit Card Setup\\n\\nEntry: Provide your credit card details in OpenAIâ€™s billing settings.\\nVerification: OpenAI verifies the card for payment processing.\\nUsage Tracking',\n",
       " 'API Requests: OpenAI tracks your usage of API models based on the number of tokens processed or requests made.\\nModel-Specific Pricing: Each model has its own token pricing (e.g., GPT-4o Mini).\\nBilling Cycle\\n\\nCycle Duration: Typically monthly. Usage is tracked continuously throughout this period.\\nAggregation: At the end of the cycle, total usage is aggregated.\\nCharges and Payment\\n\\nInvoice Generation: An invoice is generated detailing your usage and charges.\\nAutomatic Deduction: The total amount due is automatically deducted from your credit card. This usually happens at the end of the billing cycle or shortly thereafter.\\nNo Per-Request Charges: You are not charged after each individual API request; charges accumulate over the billing cycle.\\nHandling Payment Issues',\n",
       " 'Failed Payments: If thereâ€™s an issue (e.g., insufficient funds), OpenAI will notify you and may suspend or limit your access until resolved.\\nResolution: Update your payment details or resolve the issue as needed.\\nModel-Specific Pricing Example\\n\\nGPT-4o Mini Pricing:\\nInput Tokens: $0.000150 per 1,000 tokens\\nOutput Tokens: $0.000600 per 1,000 tokens\\nExample Calculation: For 10,000 input tokens and 5,000 output tokens, the total cost would be $0.0045.\\nMonitoring and Management',\n",
       " 'Dashboard: Use OpenAIâ€™s dashboard to monitor usage and manage billing settings.\\nSupport: Contact support for any billing issues or discrepancies.\\nKey Points\\nMonthly Billing: Usage is tracked monthly, and charges are applied at the end of the billing cycle.\\nModel Pricing: Charges depend on the model used and its specific token rates.\\nAutomatic Payment: Your credit card is automatically charged based on aggregated usage.\\nThis process helps in managing and understanding your API costs effectively while ensuring seamless access to OpenAIâ€™s services.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_list=list()\n",
    "for i in range(len(text)):\n",
    "    document_list.append(text[i].page_content)\n",
    "document_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a5879a-49f6-4a5e-94e8-c4ab9708c191",
   "metadata": {},
   "source": [
    "## 3) Creating Chroma DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d0c10-2e1f-4af0-905c-6f4f93e35b5c",
   "metadata": {},
   "source": [
    "- **instead of openai embeddings i am using Word2Vec embeddings bcz it is opensource**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab7b46b9-fc8b-4835-8b0d-b4cd82e557de",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'my_chroma_db' #Name or path ,,where we are going to store our embeddings related to text\n",
    "#created directory name \"my_chroma_db\" in your current working directory and inside that sql3lite named file is there,,,,,,,,inside that your vectors are going to stored\n",
    "#as u see we have not mentioned any complete path,,,,,thus in current working directory \"vector_db\" folder/directory is created and inside that,,,chroma.sqllite3 lite file is created,,and here only our vectors are stored\n",
    "#Persistent means permanent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6ac62-7643-4512-af98-47491b484f9a",
   "metadata": {},
   "source": [
    "#### a) How OpenAI Embeddings and chroma db Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "219a61a0-3acd-4454-9b87-0f400f22d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR STORING VECTORS?EMBEDDINGS INTO CHROMA DB (my_chroma_db)\n",
    "\n",
    "# openai_embedding_model = OpenAIEmbeddings()\n",
    "# vector_db = Chroma.from_documents(\n",
    "#     documents = text,\n",
    "#     embedding = embedding,\n",
    "#     persist_directory = persist_directory\n",
    "# )\n",
    "\n",
    "#If u use openai embedding model,,,,,,,then u can run above code easily,,,,,,,,,,,,,,,,bcz \n",
    "#this \"openai_emnedding_model\" will take 0ne document or text from documents parameter -> embedding.embed_query(text[i].page_content) -> get this the vector/embeddings for this sentence or document\n",
    "#and each vector is store in vector_db name database along with it's equvivalent text/document,,so at the time of retrieval it will return you just document,,no vector....but pinecone returns you vector,,and you have again revert it to text/document\n",
    "\n",
    "#from_documents() -> (present in langchain),is implemented such that ,, we have to just pass the document (see ,,text,,,same we pass it without any preprocessing)\n",
    "#ie;no need to,extract page_content,store in list and then pass it to embedding model,,,like what we done in \"document_list\"............\n",
    "#from_documents(),,implemented such that,,it will internally extract page_content and pass it to further stage.........ie; to our embedding model one by one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b8d49-df2d-412e-9f26-3fde56f31f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO ACCESS CHROMA DB (my_chroma_db),,,TO PERFORM QUERY OR QA TASK.............ypu can access my_chroma_db using above specified vector_db also,,or using below code also(ie;through retriever object vectordb).\n",
    "\n",
    "# vectordb = Chroma(\n",
    "#     persist_directory = \"my_chroma_db\", embedding_function=embedding              \n",
    "# )\n",
    "\n",
    "# retriever = vectordb.as_retriever()\n",
    "\n",
    "# docs = retriever.get_relevant_documents(\"how OpenAI tracks your usage of API?\")\n",
    "\n",
    "# docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51015b34-a1d0-48c5-bd51-9f7b201e5e5a",
   "metadata": {},
   "source": [
    "- **Entire Process** looks like this->\n",
    "- 1st- from_documents() will extract page_content from 1st document from text ,\n",
    "- 2nd- pass it to embedding model,in above case it is openai embeddings model,,where it is implemented such that,it can directly take passed document(page_content) and internally do tokenization->vectorization for each token->aggregate all words vectors to get single vector which represent passed document or page_content,and return this vector............NOTE-> extracted document is passed to openai server,there only this vectorization is done using there embedding model and after that openai will return vector w.r.t passed document...SO internet should be on,,,and **you have to pay for this service**.........this **openai embedding object has embed_documents() mehtod in it,,which internally calls openai embedding API**,,,,thus if we are using word2vec or ..etc local side embedding model then we have to implment this kind of mechanism using class to access embedding model from local side,,**see below i have implemented this mechanism for accessing local side embedding model**\n",
    "- 3rd- from_documents()  will take  this returned vector and store it in **my_chroma_db -> chroma.sqllite3**\n",
    "- and these 3 process is repeated untill all documents from text is processed\n",
    "- and finally from_documents() will return **vector_db object or pointer**,,through which we can access my_chroma_db to perform QA or query on stored vectors or embeddings\n",
    "- **but we cant do same thing with w2v,bcz we have manually do word tokenization -> converting each word into vector -> aggregating all words vector to form single vector which represent the passed document or sentence,,,so we have to write some code manually**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412468d1-b763-46f8-8b70-3a167077c425",
   "metadata": {},
   "source": [
    "#### b) Doing same thing with Word2Vec,,,which is downloaded pretrained embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4dc44f-cc7b-4d6b-9132-160dd402daeb",
   "metadata": {},
   "source": [
    "##### b.1) Incorrect way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a1fb0e4-98e0-441c-b59e-b3d102d80330",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,KeyedVectors\n",
    "path = r\"D:\\GENERATIVE-AI\\004_VectorDB\\Word2Vec_Model_300\\GoogleNews-vectors-negative300.bin.gz\"\n",
    "w2v_embedding_model = KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e2f2ad2-7ca2-4699-80d2-523a1acd2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert documents to embeddings\n",
    "def document_to_embedding(doc, model):\n",
    "    words = doc.split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Create embeddings for all documents\n",
    "embeddings = [document_to_embedding(doc, w2v_embedding_model) for doc in document_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c3054b8-86ba-4c7e-91b6-ed5df3aa7cbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 4.20454070e-02,  1.54501870e-02,  5.30535057e-02,  1.00846082e-01,\n",
       "        -6.73474446e-02,  4.49416004e-02,  6.63796365e-02, -5.88520318e-02,\n",
       "         4.44916524e-02,  5.55446893e-02, -6.68885782e-02, -6.30467087e-02,\n",
       "        -5.31262644e-02, -5.25721116e-03, -7.93680325e-02,  1.16814777e-01,\n",
       "         9.85055342e-02,  7.44783357e-02,  1.46714188e-02, -2.76448317e-02,\n",
       "        -6.18413351e-02,  9.28246137e-03,  4.58155386e-02,  2.25885911e-03,\n",
       "         2.54410300e-02,  4.93529160e-03, -1.02348655e-01,  5.60542792e-02,\n",
       "         2.09426880e-03, -8.96844640e-03, -3.97800356e-02, -3.04915267e-03,\n",
       "        -2.99420711e-02, -1.03935618e-02, -2.25857995e-03, -2.52478067e-02,\n",
       "         1.48092126e-02,  2.58752778e-02,  2.40009595e-02,  4.30617929e-02,\n",
       "         7.35564828e-02, -3.53977866e-02,  1.30084619e-01, -3.62702794e-02,\n",
       "        -4.06904938e-03, -7.17198327e-02, -2.71792524e-03,  1.29923476e-02,\n",
       "         1.42405443e-02, -1.68489590e-02, -1.67753641e-02,  6.15480021e-02,\n",
       "        -3.79981066e-04, -2.17322372e-02,  7.54548283e-03,  3.39225195e-02,\n",
       "        -5.32116778e-02, -4.56895605e-02,  6.16151765e-02, -4.14097495e-02,\n",
       "        -2.69129686e-02,  4.60435338e-02, -1.10088810e-01, -5.69098853e-02,\n",
       "        -5.51028363e-03, -4.08656411e-02, -5.11325784e-02,  7.35453144e-02,\n",
       "        -5.85528128e-02,  5.23720719e-02,  7.27702826e-02,  3.47809680e-02,\n",
       "         9.39734876e-02, -2.90253796e-02, -9.64878350e-02, -8.72936025e-02,\n",
       "         9.19329002e-02,  1.04832344e-01,  1.47790676e-02,  1.10091977e-01,\n",
       "         2.04393337e-03, -7.36411512e-02,  4.64414023e-02,  4.58686650e-02,\n",
       "        -2.39484832e-02, -5.38588725e-02, -5.17252497e-02,  1.22939505e-01,\n",
       "         1.87067166e-02,  4.98270169e-02,  5.78378811e-02,  3.87087576e-02,\n",
       "        -5.19347303e-02, -1.43759385e-01, -2.89827678e-02, -8.62343982e-02,\n",
       "         6.29105493e-02,  7.55432844e-02,  6.03887029e-02,  1.91562008e-02,\n",
       "        -3.19784917e-02, -4.95394729e-02,  4.07149130e-03,  3.56817469e-02,\n",
       "        -7.87234455e-02, -2.83143576e-02, -4.68147099e-02, -5.97195514e-02,\n",
       "         3.71068157e-02, -6.14504218e-02, -5.53734004e-02, -6.30775094e-02,\n",
       "        -4.16669138e-02, -3.38691138e-02,  2.16108188e-02,  3.02905571e-02,\n",
       "         3.73811945e-02, -3.99575569e-02,  1.18509382e-01,  4.68842648e-02,\n",
       "        -2.28476170e-02, -3.98060866e-02, -4.38831598e-02,  9.64428037e-02,\n",
       "         3.81231532e-02, -3.61498399e-03, -5.06651327e-02, -1.06837573e-02,\n",
       "         3.85812894e-02, -4.71347710e-04, -4.62575294e-02, -1.00328483e-01,\n",
       "        -7.48473406e-02, -4.25482020e-02, -2.80290004e-02, -8.01626071e-02,\n",
       "         3.15070748e-02,  2.52279881e-02,  9.12698917e-03,  8.67588669e-02,\n",
       "         2.21412480e-02, -8.39648396e-02,  4.61336449e-02,  6.28885394e-03,\n",
       "         2.53757387e-02, -1.84292216e-02, -2.87959408e-02, -9.85420048e-02,\n",
       "        -6.02042973e-02, -4.00215723e-02,  5.38869724e-02,  4.84157652e-02,\n",
       "        -7.26852491e-02, -5.75675024e-03,  4.58833645e-04, -1.17453597e-02,\n",
       "         1.25186965e-02, -3.45730782e-02, -6.56481460e-02,  9.04040225e-03,\n",
       "         1.39389038e-02,  7.53389671e-02,  1.08941244e-02,  4.79914956e-02,\n",
       "         3.01826280e-03, -7.01074377e-02,  4.92677912e-02, -4.32928614e-02,\n",
       "        -9.32181778e-04, -3.66289094e-02, -1.56431437e-01, -6.39805198e-02,\n",
       "        -4.25954685e-02, -7.64189959e-02, -5.07323109e-02, -1.26580959e-02,\n",
       "         9.34693888e-02, -9.60110947e-02, -2.98616365e-02,  3.11656576e-02,\n",
       "        -1.03799239e-01, -2.36918759e-02,  1.05654085e-02,  2.94283424e-02,\n",
       "         1.99480751e-03, -4.10602838e-02, -4.54636328e-02,  2.63984501e-02,\n",
       "         5.32684326e-02,  7.65280351e-02,  5.79629280e-03,  1.65836979e-02,\n",
       "        -3.96773182e-02, -3.78667302e-02, -5.61002409e-03,  3.07144541e-02,\n",
       "        -2.03989539e-02, -4.23316956e-02, -6.31687790e-02, -1.37156039e-01,\n",
       "         4.41738218e-02,  7.18986467e-02, -6.51946738e-02,  3.83428000e-02,\n",
       "        -2.62025967e-02,  3.41878757e-02, -7.93678463e-02, -1.26333470e-02,\n",
       "         2.90156566e-02, -7.18540093e-03,  1.86672676e-02,  8.89743716e-02,\n",
       "        -4.20874618e-02,  5.91538139e-02, -1.13657512e-01,  6.31997213e-02,\n",
       "         1.10131986e-01, -1.52770020e-02, -1.24503627e-01,  2.07672119e-02,\n",
       "        -7.44582387e-03, -1.29413139e-02, -3.27140540e-02, -6.16334118e-02,\n",
       "         4.97283004e-02,  1.02840513e-02,  3.45171951e-02,  1.45833082e-02,\n",
       "        -1.03375502e-02,  1.05203772e-02, -1.76205523e-02, -5.59975244e-02,\n",
       "         4.19698581e-02,  4.04716060e-02,  3.90462168e-02, -1.69037608e-03,\n",
       "         1.03806285e-02, -4.77434471e-02,  7.55380765e-02, -1.63864507e-03,\n",
       "         4.14339378e-02,  2.05008816e-02,  4.19283621e-02, -1.24243408e-01,\n",
       "        -8.88061523e-03, -8.37372590e-06, -1.29911844e-02,  1.08498923e-01,\n",
       "         2.64273845e-02, -7.44651258e-02,  3.42984088e-02,  2.09415257e-02,\n",
       "         2.83458065e-02,  3.22372988e-02,  3.64175178e-02,  2.06438396e-02,\n",
       "         5.87634593e-02,  1.70139223e-02, -5.58795482e-02, -1.81819629e-02,\n",
       "         2.92941760e-02, -4.51665744e-02, -1.03227571e-01,  2.11311895e-02,\n",
       "         8.26514605e-03,  1.10407017e-01, -3.35093699e-02, -9.46212374e-03,\n",
       "        -5.79495318e-02, -1.69593059e-02,  3.81611139e-02,  1.18545905e-01,\n",
       "         9.81288999e-02,  8.16825330e-02,  5.75505681e-02, -1.45794004e-02,\n",
       "        -4.91426066e-02, -1.38921976e-01, -4.72397208e-02, -2.24214569e-02,\n",
       "        -1.10860681e-02, -8.35083798e-03,  4.75240573e-02,  5.04884496e-02,\n",
       "         1.47682745e-02,  1.40439011e-02, -3.93980071e-02, -3.27094011e-02,\n",
       "         3.20248492e-02,  4.37642522e-02, -7.40279257e-02,  6.13619164e-02,\n",
       "        -8.91625956e-02, -1.30868303e-02,  1.00662420e-02,  2.32177358e-02,\n",
       "        -4.74408781e-03, -5.30103371e-02, -9.26310848e-03, -2.86299083e-02],\n",
       "       dtype=float32),\n",
       " array([ 2.27461755e-02,  1.14711765e-02,  3.45583074e-02,  1.06182456e-01,\n",
       "        -3.07259113e-02,  4.71276864e-02,  4.39953618e-02, -3.99194323e-02,\n",
       "         2.28663124e-02,  2.57104486e-02, -9.78877768e-02, -5.46732582e-02,\n",
       "        -2.56014001e-02,  2.54197177e-02, -6.73938021e-02,  5.45465611e-02,\n",
       "         1.03998207e-01,  5.03250137e-02, -1.78727210e-02, -3.10548916e-02,\n",
       "        -3.29885371e-02,  1.04728192e-02, -4.33878601e-03,  3.54678333e-02,\n",
       "         2.72745769e-02,  1.00606279e-02, -8.98118094e-02,  7.67321810e-02,\n",
       "         2.52093505e-02,  5.36645502e-02, -3.72129306e-02, -6.83260113e-02,\n",
       "         6.58264151e-04, -1.67478807e-02, -9.80916340e-03, -4.26941924e-02,\n",
       "        -4.25455719e-03, -2.65274048e-02,  4.91612731e-03,  6.02624528e-02,\n",
       "         5.50740547e-02, -5.16575128e-02,  1.06762901e-01, -3.82815562e-02,\n",
       "        -2.06593834e-02, -1.42727658e-01, -1.13765458e-02,  2.73198448e-02,\n",
       "        -1.23595176e-02, -1.94643140e-02, -4.11149077e-02,  1.22770183e-02,\n",
       "        -1.61185712e-02, -7.29031861e-02, -2.12587491e-02,  5.55561334e-02,\n",
       "        -8.11702460e-02, -3.32649723e-02,  6.62276223e-02, -3.04595940e-02,\n",
       "        -3.49424221e-02,  4.12988290e-02, -1.04326986e-01, -5.91788739e-02,\n",
       "         8.39213096e-03, -1.09810382e-02, -7.57960007e-02,  6.90738931e-02,\n",
       "        -2.56941728e-02,  1.05476892e-02,  6.11888617e-02,  2.21678670e-02,\n",
       "         1.07364245e-01, -3.99172977e-02, -4.85164374e-02, -1.28361747e-01,\n",
       "         1.34532183e-01,  9.87679064e-02,  6.66605635e-03,  9.83911157e-02,\n",
       "        -3.82437394e-03, -1.09087065e-01,  2.65063215e-02,  7.52235949e-02,\n",
       "         1.52900694e-02, -6.20443709e-02, -5.77399693e-02,  7.71899447e-02,\n",
       "         5.26529970e-03,  6.88106269e-02,  7.06990585e-02,  5.16486615e-02,\n",
       "        -4.96491492e-02, -1.59288734e-01, -3.08419801e-02, -6.11002594e-02,\n",
       "         2.92175859e-02,  5.72379567e-02,  4.65641282e-02,  2.79315189e-02,\n",
       "         3.66782397e-02, -1.10267945e-01, -2.19072476e-02, -2.78542079e-02,\n",
       "        -9.17305499e-02, -2.01143399e-02, -5.99865727e-02, -3.89815271e-02,\n",
       "         2.33593751e-02, -4.12305705e-02, -3.93850692e-02, -6.28404766e-02,\n",
       "        -7.27335587e-02, -5.25431298e-02,  2.03910321e-02,  1.04139812e-01,\n",
       "        -5.65592454e-05,  2.28794347e-02,  1.69495851e-01,  5.86987287e-02,\n",
       "        -2.35640462e-02, -2.77091470e-02, -4.54611443e-02,  9.51829031e-02,\n",
       "         2.53133127e-03,  1.01924641e-02, -6.90828487e-02,  2.75602713e-02,\n",
       "         2.04827879e-02,  2.71734614e-02, -3.39900702e-02, -7.24565536e-02,\n",
       "        -1.03313804e-01, -7.31815621e-02, -4.38110344e-03, -9.49060023e-02,\n",
       "         1.03303464e-02, -2.07526404e-02, -2.56719962e-02,  9.31619778e-02,\n",
       "        -1.41382851e-02, -8.81616175e-02, -1.19603602e-02,  4.62180600e-02,\n",
       "         4.63720709e-02, -5.33565469e-02,  8.57116655e-03, -4.47430424e-02,\n",
       "        -4.44403067e-02, -8.53810646e-03,  6.50793463e-02,  3.48183177e-02,\n",
       "        -4.11067717e-02, -9.86002572e-03,  2.78500877e-02, -3.65814194e-02,\n",
       "        -6.15681987e-03, -2.99088545e-02, -7.74202496e-02, -1.41436765e-02,\n",
       "        -2.95857736e-03,  4.95385751e-02,  1.55646773e-02,  2.11678054e-02,\n",
       "        -3.03247571e-02, -6.72851549e-03,  3.05021163e-02, -5.59625253e-02,\n",
       "        -3.43575925e-02,  7.15189613e-03, -1.38391107e-01, -8.98413062e-02,\n",
       "        -2.22721361e-02, -7.41063431e-02, -6.74582943e-02, -4.24818434e-02,\n",
       "         4.88427728e-02, -7.33129904e-02, -1.98029578e-02, -1.76308695e-02,\n",
       "        -1.19693831e-01, -1.40732825e-02, -1.55505370e-02,  5.22773229e-02,\n",
       "        -2.50384528e-02, -8.46937075e-02, -6.42472804e-02,  2.61018872e-02,\n",
       "         2.76637785e-02,  8.96855667e-02, -4.54860441e-02, -4.84008779e-04,\n",
       "        -6.45951852e-02, -7.54315183e-02, -3.11401375e-02,  4.61832695e-02,\n",
       "        -4.76968884e-02, -6.25179037e-02, -4.82881665e-02, -2.00241297e-01,\n",
       "         4.01200354e-02,  9.92732719e-02, -6.56168610e-02,  3.82336415e-02,\n",
       "        -8.11482780e-03,  5.74932843e-02, -1.17807977e-01, -1.19132483e-02,\n",
       "         4.66428623e-02, -4.21535224e-02,  1.19755045e-02,  7.33219385e-02,\n",
       "        -4.14294451e-02,  8.18534866e-02, -1.31537676e-01,  8.01812708e-02,\n",
       "         8.62373859e-02,  3.99770476e-02, -1.38237715e-01, -8.18135589e-03,\n",
       "        -4.25048824e-03,  3.01795453e-02, -4.68558259e-02, -1.27771810e-01,\n",
       "         5.67016611e-03,  3.91503908e-02,  3.05745434e-02,  2.50406913e-03,\n",
       "        -2.31542960e-02, -2.96870414e-02, -2.72733569e-02, -2.59399414e-02,\n",
       "         7.74438456e-02,  2.88817659e-02, -1.63011681e-02, -3.72351073e-02,\n",
       "         1.71879064e-02, -1.94698088e-02,  4.87211086e-02,  7.87394214e-03,\n",
       "        -1.26161706e-02,  1.90751646e-02,  8.27787295e-02, -1.41614020e-01,\n",
       "         2.69246427e-03, -2.29528807e-02, -1.28784180e-02,  1.30858973e-01,\n",
       "        -1.96091216e-02, -7.94571936e-02,  1.43636062e-04,  2.50608828e-02,\n",
       "        -3.68251540e-02, -3.46679677e-04,  3.18847666e-03,  4.95994054e-02,\n",
       "         1.92086790e-02,  2.15856936e-02, -6.36803210e-02, -4.87365723e-02,\n",
       "         7.92862922e-02, -4.57149260e-02, -1.00301109e-01, -6.31698593e-03,\n",
       "        -1.76645920e-03,  7.33007789e-02, -5.12992367e-02,  1.24070235e-02,\n",
       "        -6.95161968e-02, -6.40320852e-02,  1.90417487e-02,  1.07365720e-01,\n",
       "         9.47591104e-03,  6.32226542e-02,  3.10947411e-02, -3.46970633e-02,\n",
       "        -3.40826400e-02, -9.33219418e-02, -4.64034006e-02,  1.27594341e-02,\n",
       "        -3.83428577e-03, -1.05891926e-02,  4.50496413e-02,  8.25370252e-02,\n",
       "         3.87776690e-03,  4.06511426e-02, -3.45735662e-02,  1.98950190e-02,\n",
       "         3.87912989e-02,  6.40011579e-02, -5.26350923e-02,  7.73132294e-02,\n",
       "        -6.67919889e-02, -1.78938806e-02, -7.91849755e-03,  1.28115332e-02,\n",
       "         1.54017126e-02, -7.10585043e-02, -2.70676669e-02, -2.41348264e-03],\n",
       "       dtype=float32),\n",
       " array([ 0.01449339,  0.0315478 ,  0.03246018,  0.07135659, -0.04078148,\n",
       "         0.00907617,  0.0446281 , -0.04719561,  0.0602937 ,  0.0521242 ,\n",
       "        -0.04954932, -0.0729093 , -0.01789505,  0.02447966, -0.07242987,\n",
       "         0.02975674,  0.07914787,  0.05223855, -0.00599076, -0.02487674,\n",
       "        -0.0550128 ,  0.03005631, -0.03537338,  0.06616855,  0.02909702,\n",
       "        -0.01374462, -0.07560151,  0.10934764,  0.02933432,  0.01737257,\n",
       "        -0.01933052, -0.06135322, -0.01585357, -0.01996069,  0.01978547,\n",
       "        -0.04760014, -0.0162778 , -0.01988159,  0.02500723,  0.0114027 ,\n",
       "         0.06777814, -0.02277716,  0.05093699, -0.03134046, -0.00380794,\n",
       "        -0.10578173, -0.03297372,  0.03893942, -0.00913581,  0.02364095,\n",
       "        -0.02096277, -0.01970559, -0.0055107 , -0.04495976, -0.00401867,\n",
       "         0.09065606, -0.06217159, -0.05857832,  0.05277033, -0.01718771,\n",
       "        -0.06772815,  0.05771466, -0.10197256, -0.08465366, -0.0045123 ,\n",
       "        -0.01639618, -0.03705974,  0.06950628, -0.05406469,  0.021678  ,\n",
       "         0.04497414, -0.02394709,  0.07625641, -0.01475218, -0.03426458,\n",
       "        -0.09891652,  0.11951263,  0.05114431,  0.01019015,  0.1033241 ,\n",
       "         0.02634362, -0.11247166,  0.0110186 ,  0.034729  ,  0.00387398,\n",
       "        -0.09838797, -0.06357408,  0.10384676,  0.00712252,  0.06346393,\n",
       "         0.06554983,  0.02696658, -0.055321  , -0.13689922, -0.02376017,\n",
       "        -0.00430877,  0.01778724, -0.02333257,  0.02658888,  0.03223954,\n",
       "         0.0648385 , -0.11998389, -0.00971915, -0.05472609, -0.05693857,\n",
       "        -0.01640855, -0.10508272, -0.00184719,  0.01474245, -0.06281327,\n",
       "        -0.00843127, -0.073607  , -0.02645839, -0.05481395,  0.00733764,\n",
       "         0.07037915, -0.0192751 ,  0.00563593,  0.14255589,  0.08613639,\n",
       "        -0.04982113, -0.02482009, -0.04225667,  0.04808395,  0.04930676,\n",
       "         0.06202325, -0.06830544,  0.00590454,  0.0249711 ,  0.01880216,\n",
       "        -0.03751207, -0.07017815, -0.06115442, -0.07244768, -0.04113314,\n",
       "        -0.09719375, -0.00338219, -0.02720473, -0.04479066,  0.09172532,\n",
       "         0.0164481 , -0.05584506, -0.03203462,  0.0616172 ,  0.0104656 ,\n",
       "        -0.02125891,  0.05098084, -0.0378204 , -0.04351017, -0.00317804,\n",
       "         0.06904935,  0.01797227,  0.00625049,  0.0070664 , -0.00124771,\n",
       "        -0.0477116 , -0.01115225, -0.02456551, -0.07071411, -0.05056449,\n",
       "        -0.04338249,  0.05278427,  0.01299591,  0.03704417, -0.0541331 ,\n",
       "         0.02136853,  0.0101834 , -0.01307626, -0.02840878,  0.00396097,\n",
       "        -0.13854524, -0.06718743,  0.00626593, -0.09211029, -0.03238336,\n",
       "        -0.0304437 ,  0.07999546, -0.11356959, -0.0621487 , -0.03870808,\n",
       "        -0.08148266, -0.01834562, -0.0533321 ,  0.07051656,  0.00414723,\n",
       "        -0.00938223, -0.04853891,  0.08136944,  0.01330461,  0.07617933,\n",
       "         0.00887158, -0.02197985, -0.0585538 , -0.03693644, -0.10311364,\n",
       "        -0.00274869, -0.04239457, -0.05372109, -0.04267778, -0.13835022,\n",
       "         0.06038974,  0.02437118, -0.03935154,  0.0235494 , -0.03186544,\n",
       "         0.07529704, -0.05942035, -0.0008259 ,  0.06923434, -0.03882722,\n",
       "         0.01498154,  0.05708681, -0.02187233,  0.07177476, -0.09857809,\n",
       "         0.05365605,  0.06922773,  0.05549131, -0.10681047, -0.00526867,\n",
       "        -0.01103386,  0.04944512, -0.04124381, -0.08491814,  0.02911894,\n",
       "         0.01053988,  0.00746418, -0.00035674,  0.03187544, -0.02066746,\n",
       "        -0.01843972, -0.01034791,  0.06765822,  0.02489392, -0.03528744,\n",
       "        -0.03747383,  0.04025409, -0.02407977,  0.03404837,  0.03382856,\n",
       "         0.02414993, -0.00488465,  0.04124872, -0.12716569, -0.01497045,\n",
       "        -0.03415268, -0.03649727,  0.14348462,  0.01903429, -0.07208106,\n",
       "         0.02725763,  0.05578771, -0.04231245,  0.02001085,  0.00693227,\n",
       "         0.00160312,  0.06072389, -0.03059054, -0.02935844, -0.05829875,\n",
       "         0.08033051, -0.03457922, -0.109256  , -0.01640921,  0.00700212,\n",
       "         0.07795031, -0.05024298,  0.02449229, -0.04896822, -0.02864417,\n",
       "         0.03379594,  0.0997118 , -0.00958546,  0.04247906,  0.02536682,\n",
       "        -0.03324206, -0.06736518, -0.04662877, -0.02815983, -0.05701908,\n",
       "        -0.04193185,  0.02634895,  0.0669293 ,  0.07731155,  0.03329819,\n",
       "         0.00613701, -0.0463883 ,  0.01568814,  0.02640525,  0.0496375 ,\n",
       "        -0.02675576,  0.04051226, -0.05276972,  0.03099253,  0.00261618,\n",
       "        -0.0014438 ,  0.01579749, -0.04030557, -0.01172278, -0.03907671],\n",
       "       dtype=float32),\n",
       " array([ 0.01804742, -0.03149414,  0.00155318,  0.10879042, -0.08624641,\n",
       "         0.07393121,  0.05990041, -0.03385959,  0.10064918,  0.01846652,\n",
       "        -0.06869778, -0.00949571,  0.01241319,  0.01052687, -0.08803067,\n",
       "         0.04900097,  0.08881684,  0.02274297,  0.02199775, -0.10383233,\n",
       "        -0.02702679,  0.01224908,  0.0034412 ,  0.09272461, -0.00102268,\n",
       "         0.04636739, -0.08377736,  0.10195584,  0.03419868,  0.00850423,\n",
       "        -0.01490139, -0.06907416, -0.05664181, -0.08230184, -0.02808431,\n",
       "        -0.0859692 ,  0.04173855, -0.02324354, -0.01135525,  0.03930867,\n",
       "         0.02306586, -0.04437358,  0.08780321, -0.02675985, -0.01338603,\n",
       "        -0.08390503, -0.01932034,  0.03081152, -0.03563758, -0.01245185,\n",
       "        -0.06113959, -0.00214437,  0.05782526, -0.04950833, -0.03854641,\n",
       "         0.03079071, -0.07766927, -0.06858181,  0.08898112, -0.02907376,\n",
       "        -0.06455214,  0.04702352, -0.09110107, -0.02763502, -0.00704346,\n",
       "        -0.0715939 , -0.0393887 ,  0.11267361, -0.00056559,  0.0339308 ,\n",
       "         0.0405393 , -0.01903114,  0.09146932,  0.00842828, -0.08143107,\n",
       "        -0.1399265 ,  0.07962545,  0.04506293,  0.02511207,  0.13816732,\n",
       "         0.03244737, -0.09676785,  0.01861636,  0.08954264,  0.00305311,\n",
       "        -0.02453817,  0.00411072,  0.07215916,  0.01626396,  0.05317315,\n",
       "         0.10052219, -0.00192362, -0.01277898, -0.12071398,  0.03760783,\n",
       "        -0.0182902 ,  0.0318278 ,  0.03087972,  0.02517768,  0.04352044,\n",
       "         0.07051315, -0.10221396, -0.02885963, -0.04358114, -0.03843113,\n",
       "         0.00875651, -0.04717848, -0.05235884, -0.00047743, -0.05374518,\n",
       "         0.00573866, -0.1200353 , -0.00896301, -0.03783841,  0.05138332,\n",
       "         0.04359063,  0.02318047,  0.00532905,  0.15790813,  0.01510586,\n",
       "         0.01951633,  0.01828749, -0.08054505,  0.060436  ,  0.01361186,\n",
       "         0.00970866, -0.05996229,  0.02567961,  0.03281013, -0.0112264 ,\n",
       "        -0.01315579, -0.03490514, -0.07957085, -0.01724514, -0.0227851 ,\n",
       "        -0.07188585, -0.03536692, -0.0557902 , -0.0382175 ,  0.13385417,\n",
       "         0.06352361, -0.05880127, -0.0521617 ,  0.01353327,  0.03298374,\n",
       "        -0.06692403,  0.02605184, -0.05453423, -0.0315294 , -0.01372003,\n",
       "         0.07188381, -0.01942613, -0.01404487, -0.00473701,  0.01617559,\n",
       "        -0.03850776, -0.00342611, -0.00597738, -0.12714641, -0.0272522 ,\n",
       "         0.01089444,  0.02985382,  0.0498213 ,  0.01331109, -0.08581568,\n",
       "         0.0419203 ,  0.02343072, -0.01090359, -0.04820048,  0.01481934,\n",
       "        -0.14958632, -0.02452799, -0.04141168, -0.09898055, -0.01196425,\n",
       "        -0.0473615 ,  0.06607921, -0.10467055, -0.072907  , -0.00845269,\n",
       "        -0.13824043, -0.01886291, -0.05893283,  0.0717136 ,  0.02223324,\n",
       "        -0.00983256, -0.05207587,  0.02085622,  0.072327  ,  0.08978824,\n",
       "        -0.06375258,  0.01202867, -0.09263662, -0.05034722, -0.07656793,\n",
       "        -0.00098606,  0.02417641, -0.08534206, -0.01574949, -0.1408421 ,\n",
       "         0.00740679,  0.08854166, -0.07473857,  0.03697916, -0.01448839,\n",
       "         0.01799467, -0.08306071, -0.01687961,  0.06245098, -0.04261369,\n",
       "        -0.00518934,  0.04131673, -0.03964979,  0.0742947 , -0.14795397,\n",
       "         0.06419746,  0.11709324,  0.02813721, -0.07861396,  0.02215508,\n",
       "        -0.05622559,  0.05474447, -0.04852295, -0.06395806,  0.00272081,\n",
       "        -0.02374675,  0.04313897,  0.02756212,  0.03708835, -0.03795607,\n",
       "        -0.03390774,  0.00027635,  0.08630371,  0.00143297,  0.01067403,\n",
       "        -0.08931749,  0.0660753 , -0.10592787,  0.06271532,  0.00349731,\n",
       "        -0.05130717,  0.04118245,  0.04385071, -0.08576592,  0.00121358,\n",
       "        -0.03289185, -0.08555705,  0.11602347,  0.011085  , -0.06495972,\n",
       "         0.04404026,  0.09527774, -0.03675673, -0.00534498,  0.01696777,\n",
       "        -0.03735352,  0.07539486, -0.04827745, -0.04995405, -0.03901672,\n",
       "         0.08140903, -0.02592841, -0.12083876,  0.00550266,  0.00347799,\n",
       "         0.03995497, -0.08258328,  0.03554077, -0.0302653 , -0.03460422,\n",
       "         0.08101501,  0.10780437,  0.05741238,  0.03817003,  0.03893161,\n",
       "        -0.0195855 , -0.05879245, -0.0882192 , -0.01850247, -0.01383175,\n",
       "        -0.03029955,  0.0336202 ,  0.10747749,  0.07072754,  0.02296787,\n",
       "        -0.0027181 , -0.06991509,  0.04393344,  0.03358019,  0.02761063,\n",
       "        -0.02377116,  0.02251333, -0.06019677,  0.0118571 ,  0.00641276,\n",
       "         0.05717638, -0.04567786, -0.08856439, -0.02225486, -0.03936903],\n",
       "       dtype=float32),\n",
       " array([ 8.21122993e-03,  3.42972553e-03,  1.86397359e-02,  4.13828380e-02,\n",
       "        -4.83368412e-02,  2.75837630e-02,  5.00878505e-02, -3.94799449e-02,\n",
       "         3.63489352e-02,  1.88386627e-02, -6.12437762e-02, -3.00818272e-02,\n",
       "        -2.47349981e-02,  2.58263759e-02, -7.74105862e-02,  2.06453912e-02,\n",
       "         1.05801441e-01,  4.83277738e-02, -2.79558524e-02, -5.29079735e-02,\n",
       "        -4.06484120e-02,  1.74417961e-02, -3.53778787e-02,  1.03959009e-01,\n",
       "         1.46589437e-02, -7.54834805e-03, -9.65603665e-02,  1.29255950e-01,\n",
       "         2.70879772e-02, -1.51807442e-02,  1.87863205e-02, -7.83914030e-02,\n",
       "        -7.23716849e-03, -2.95675304e-02,  4.71370257e-02, -4.21407744e-02,\n",
       "        -6.74851192e-03, -2.17684135e-02,  3.12479995e-02, -4.05433541e-03,\n",
       "         2.67609134e-02, -2.52235290e-02,  5.48901185e-02, -1.57090481e-02,\n",
       "        -5.87619701e-03, -1.19503662e-01, -3.12083513e-02,  2.92918719e-02,\n",
       "         9.04971268e-03,  3.97611521e-02, -3.85584608e-02, -1.44051723e-02,\n",
       "        -3.91900726e-03, -7.49664307e-02, -1.52767990e-02,  7.05375075e-02,\n",
       "        -9.44200084e-02, -6.98259696e-02,  6.10256493e-02, -5.98644838e-03,\n",
       "        -6.18888997e-02,  3.07982396e-02, -1.18927628e-01, -5.79311177e-02,\n",
       "         1.13295261e-02,  1.93846654e-02, -4.81561124e-02,  7.24209622e-02,\n",
       "        -1.77857447e-02,  1.04975468e-02,  4.70696129e-02, -2.81752292e-02,\n",
       "         1.10006362e-01, -4.18219641e-02, -3.73987928e-02, -1.32946983e-01,\n",
       "         1.16118886e-01,  6.65298179e-02,  2.49653794e-02,  1.01352379e-01,\n",
       "         1.51737398e-02, -4.40743864e-02,  3.06676645e-02,  3.72389480e-02,\n",
       "         5.54904640e-02, -1.06111869e-01, -9.51688141e-02,  4.50999774e-02,\n",
       "         1.85106625e-03,  6.51320145e-02,  8.29227641e-02, -7.72544974e-03,\n",
       "        -3.36780250e-02, -1.42588511e-01, -9.61766485e-03, -1.27198268e-03,\n",
       "         2.07359437e-02, -1.92442089e-02,  2.12209728e-02,  3.95642892e-02,\n",
       "         5.62990829e-02, -9.61852148e-02,  1.10287592e-02, -4.42700014e-02,\n",
       "        -7.40051270e-02,  1.23508635e-03, -9.34678391e-02, -6.80767116e-04,\n",
       "         3.42657380e-02, -5.86440302e-02, -3.11554447e-02, -6.29027337e-02,\n",
       "        -9.13178176e-02, -6.45559356e-02,  1.64774917e-02,  7.01414049e-02,\n",
       "         1.05027994e-02,  4.75273773e-05,  1.15997687e-01,  7.33302385e-02,\n",
       "        -3.67334075e-02,  2.77972617e-03, -4.49568965e-02,  5.37527129e-02,\n",
       "         2.27581095e-02,  2.01132726e-02, -4.65725772e-02,  3.62979062e-02,\n",
       "         2.38905102e-02,  3.25952731e-02, -3.08757853e-02, -7.47533068e-02,\n",
       "        -5.95037751e-02, -3.56470309e-02, -1.69156175e-02, -9.73263085e-02,\n",
       "         4.24171835e-02, -4.78325505e-03, -5.29805161e-02,  7.25958124e-02,\n",
       "         5.75954877e-02, -2.89206579e-02, -4.75255139e-02,  5.15561961e-02,\n",
       "         2.78415363e-02, -3.12979035e-02,  2.65162736e-02, -2.72535738e-02,\n",
       "        -1.15216360e-03,  2.43212599e-02,  7.56130219e-02,  6.43285513e-02,\n",
       "         8.77455436e-03,  1.04380120e-02,  7.44087948e-03, -2.21947841e-02,\n",
       "        -4.86079976e-02, -1.51227107e-02, -6.78682923e-02, -5.09288348e-02,\n",
       "        -1.53213250e-03,  5.31010851e-02,  1.30697777e-02,  2.63536796e-02,\n",
       "        -6.65705949e-02,  3.51842679e-02, -2.50894518e-04, -4.35839556e-02,\n",
       "        -5.24777267e-03, -1.49926357e-02, -1.24349624e-01, -6.31461218e-02,\n",
       "        -5.03990287e-03, -1.03500865e-01, -9.88394301e-03, -1.00285262e-02,\n",
       "         9.53849107e-02, -1.13929875e-01, -1.15249135e-01, -1.66863613e-02,\n",
       "        -1.43036395e-01, -2.63741910e-02, -2.52958201e-02,  2.66813692e-02,\n",
       "        -2.26758104e-02, -1.90422181e-02, -4.28755730e-02,  3.56185175e-02,\n",
       "         8.63697473e-03,  6.63041919e-02, -3.30025107e-02, -5.06164059e-02,\n",
       "        -2.11681928e-02, -4.97934297e-02, -1.12593792e-01,  2.34109852e-02,\n",
       "        -2.92833038e-02, -7.80620873e-02,  1.95382535e-02, -1.55849770e-01,\n",
       "         6.12993091e-02,  4.77134846e-02, -3.81347165e-02,  1.04180006e-02,\n",
       "        -4.16311361e-02,  3.67636755e-02, -4.86887954e-02, -1.63759328e-02,\n",
       "         5.47397174e-02, -5.08921109e-02,  3.31440917e-03,  6.87005743e-02,\n",
       "        -3.84366401e-02,  7.90612921e-02, -6.13583438e-02,  1.01648942e-02,\n",
       "         1.03439115e-01,  5.48404790e-02, -1.20198235e-01, -2.81721018e-02,\n",
       "        -4.23641503e-02,  3.60772796e-02, -5.34859337e-02, -1.03173681e-01,\n",
       "        -3.48809659e-02,  1.17831621e-02,  1.75956357e-02,  1.03752259e-02,\n",
       "         7.61063350e-03, -2.78422255e-02, -2.02600453e-02, -2.36876439e-02,\n",
       "         7.44597018e-02,  2.25619096e-02, -1.53500913e-03, -6.18133545e-02,\n",
       "         1.97778922e-02, -2.67238934e-02,  3.79098989e-02,  3.28103974e-02,\n",
       "         2.66718622e-02, -1.24040199e-03,  2.01110840e-02, -1.06053583e-01,\n",
       "        -3.48075479e-02, -3.18592265e-02, -3.83110680e-02,  1.32678926e-01,\n",
       "        -7.35198474e-03, -9.17598531e-02, -9.76187270e-03,  6.78758472e-02,\n",
       "        -2.87157912e-02,  3.63373049e-02,  1.18113030e-02,  8.47012922e-03,\n",
       "         4.92158486e-03,  1.46684493e-03, -5.04327975e-02, -5.01011088e-02,\n",
       "         6.78110570e-02, -2.62161009e-02, -8.97689536e-02,  1.96250547e-02,\n",
       "         2.57256925e-02,  6.89787343e-02, -3.70977446e-02, -1.70518216e-02,\n",
       "        -6.46622479e-02, -5.09578511e-02,  4.23038676e-02,  7.85962716e-02,\n",
       "        -1.93258189e-02,  4.50529493e-02,  3.79202180e-02, -3.16079557e-02,\n",
       "        -5.33247143e-02, -3.73917893e-02, -2.88241021e-02, -3.81579772e-02,\n",
       "        -4.32469100e-02,  3.85276936e-02,  5.65518253e-02,  9.76432413e-02,\n",
       "         9.55550373e-03,  2.19041165e-02, -5.09933718e-02,  4.11350690e-02,\n",
       "         9.19602215e-02,  1.14160758e-02, -3.23309973e-02,  6.12587854e-02,\n",
       "        -2.25574933e-02,  4.65973392e-02, -2.10181065e-02,  2.42217649e-02,\n",
       "         2.86413729e-02, -2.15634201e-02,  8.55317619e-03,  6.87370915e-03],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e6bda40-1bdd-4f57-bfc6-51f0ddd09ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_db = Chroma.from_documents(\n",
    "#     documents = text,\n",
    "#     embedding = embeddings,\n",
    "#     persist_directory = persist_directory\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2079fd-78ba-40ab-81f1-1b3170eb1b7d",
   "metadata": {},
   "source": [
    "- above code gives you error,bcz\n",
    "- The error occurs because Chroma expects an embedding function, not precomputed embeddings. Let's modify the approach to provide a custom embedding function that Chroma can use to compute embeddings on the fly.\n",
    "- **so we have to implement embed_document() method which calls this word2vec model**\n",
    "- **We will define a custom embedding class that integrates with Chroma. This class should have an embed_documents method that Chroma can call.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce669020-03e5-42f9-b746-843f748d80fc",
   "metadata": {},
   "source": [
    "##### b.2) Correct Way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c20fbd-d3a5-48fb-9a55-c19df5e18eae",
   "metadata": {},
   "source": [
    "- **NOTE-> from_documents(),,will store vector/embeddings along with their equvivalent document/text**,,thus, **when u query something(using retriever.get_relevant_documents()),,then first that query is vectorized and then passed it to chroma db,,there it will do similarity matching b/n queried vector(vector of question asked) and other stored vectors,,,and return more similar Document.....(not return the vector,,,,,this is the beautiful thing of chroma db,,,,so no need to revert back vector to text/document again)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4adc2ed-a03e-4aa5-9aac-ded98ae1f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert documents to embeddings\n",
    "def document_to_embedding(doc, model):\n",
    "    words = doc.split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if not word_vectors:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0).tolist()\n",
    "\n",
    "# Custom embedding class\n",
    "class Word2VecEmbeddings:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def embed_documents(self, docs): #\"from_documents()\" ..method will need this function to create embedding while storing in to vector db\n",
    "        return [document_to_embedding(doc, self.model) for doc in docs]\n",
    "\n",
    "    def embed_query(self, query): #when you query/question something using \"retriever.get_relevant_documents()\",,,then ,first you have to convert it to vectors then pass it to chroma db for similarity matching,,,,,,and most similar document is returned\n",
    "        return document_to_embedding(query, self.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91527318-7fe5-470f-9733-72c1668595b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_embedding = Word2VecEmbeddings(w2v_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92b92d57-3d1e-4916-881f-96b175a09d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = Chroma.from_documents(\n",
    "    documents=text,\n",
    "    embedding=word2vec_embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeb5b8a1-8c27-412c-bc33-dcb0c8291b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shree\\.conda\\envs\\playing_with_genai\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Optionally, you can persist the vector database to disk\n",
    "vector_db.persist()\n",
    "#Stored successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b53eb-beca-4572-8361-8c9def0c3d11",
   "metadata": {},
   "source": [
    "## 4) Querying or Implementing QA System on stored Vectors/embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b35c0-6ddd-4a1e-b67a-f6c19c8bf70c",
   "metadata": {},
   "source": [
    "- **Biggest Disadvantage with chroma db is,,it will store these vetor as binary files (BIN file).......so u cant see it,,as u see in pinecone**\n",
    "- in backend,,**chroma db uses chroma.sqllite3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30cf319-9be2-478a-9d09-a87b629ed32b",
   "metadata": {},
   "source": [
    "### 4.1)Load the persisted DB from disk(path where you created this my_chroma_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d14f1df-97b1-4a05-84b7-5dd353f0d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory = \"my_chroma_db\", embedding_function=word2vec_embedding              \n",
    ")\n",
    "#embedding_function=word2vec_embedding -> compulsorly you have to pass it,,,bcz when you query something,,at that time ,,\n",
    "#to convert that query to vector,,it will internally use this model,,and embed_query mehthod of this \"word2vec_embedding\" object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f127d8e-fd68-4b11-a31e-5e4d685a2542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x23d41bda610>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb\n",
    "#pointer or object to access my_chroma_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cea804-c9a6-4f8a-9701-57bc45b3e972",
   "metadata": {},
   "source": [
    "### 4.2) Make a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ed64e77-3ec8-4daf-98e6-da669a22d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={'k':2})\n",
    "#Top 2 most similar vectors are selected and return the corresponding document/text which is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d6dffdb-1380-45f8-8fd4-f8a3d84ecf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question/query\n",
    "docs = retriever.get_relevant_documents(\"how OpenAI tracks your usage of API?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8078f8a-cadf-4b27-9fd6-ff61010e46ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content='API Requests: OpenAI tracks your usage of API models based on the number of tokens processed or requests made.\\nModel-Specific Pricing: Each model has its own token pricing (e.g., GPT-4o Mini).\\nBilling Cycle\\n\\nCycle Duration: Typically monthly. Usage is tracked continuously throughout this period.\\nAggregation: At the end of the cycle, total usage is aggregated.\\nCharges and Payment\\n\\nInvoice Generation: An invoice is generated detailing your usage and charges.\\nAutomatic Deduction: The total amount due is automatically deducted from your credit card. This usually happens at the end of the billing cycle or shortly thereafter.\\nNo Per-Request Charges: You are not charged after each individual API request; charges accumulate over the billing cycle.\\nHandling Payment Issues'),\n",
       " Document(metadata={'source': 'Resume_Data\\\\How_Billing_works_in_OpenAI.txt'}, page_content='API Requests: OpenAI tracks your usage of API models based on the number of tokens processed or requests made.\\nModel-Specific Pricing: Each model has its own token pricing (e.g., GPT-4o Mini).\\nBilling Cycle\\n\\nCycle Duration: Typically monthly. Usage is tracked continuously throughout this period.\\nAggregation: At the end of the cycle, total usage is aggregated.\\nCharges and Payment\\n\\nInvoice Generation: An invoice is generated detailing your usage and charges.\\nAutomatic Deduction: The total amount due is automatically deducted from your credit card. This usually happens at the end of the billing cycle or shortly thereafter.\\nNo Per-Request Charges: You are not charged after each individual API request; charges accumulate over the billing cycle.\\nHandling Payment Issues')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Answer\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22e09ba6-8764-437f-98b0-3b83c9ee8e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b85e2d82-193c-4c84-9ed5-bedd9ba0036a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'API Requests: OpenAI tracks your usage of API models based on the number of tokens processed or requests made.\\nModel-Specific Pricing: Each model has its own token pricing (e.g., GPT-4o Mini).\\nBilling Cycle\\n\\nCycle Duration: Typically monthly. Usage is tracked continuously throughout this period.\\nAggregation: At the end of the cycle, total usage is aggregated.\\nCharges and Payment\\n\\nInvoice Generation: An invoice is generated detailing your usage and charges.\\nAutomatic Deduction: The total amount due is automatically deducted from your credit card. This usually happens at the end of the billing cycle or shortly thereafter.\\nNo Per-Request Charges: You are not charged after each individual API request; charges accumulate over the billing cycle.\\nHandling Payment Issues'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  1st most similar document\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c125b27-1c96-479e-8727-8b6cb1e05c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'API Requests: OpenAI tracks your usage of API models based on the number of tokens processed or requests made.\\nModel-Specific Pricing: Each model has its own token pricing (e.g., GPT-4o Mini).\\nBilling Cycle\\n\\nCycle Duration: Typically monthly. Usage is tracked continuously throughout this period.\\nAggregation: At the end of the cycle, total usage is aggregated.\\nCharges and Payment\\n\\nInvoice Generation: An invoice is generated detailing your usage and charges.\\nAutomatic Deduction: The total amount due is automatically deducted from your credit card. This usually happens at the end of the billing cycle or shortly thereafter.\\nNo Per-Request Charges: You are not charged after each individual API request; charges accumulate over the billing cycle.\\nHandling Payment Issues'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd most similar document\n",
    "docs[1].page_content\n",
    "#i dont know why it is giving same respoonse..\n",
    "#but it is giving more accurate document only,as u see"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51adf4-15eb-4e7c-96ec-862d5abae2b2",
   "metadata": {},
   "source": [
    "- as u see we asked **\"how OpenAI tracks your usage of API?\"**,,,,,and we get response which contains answer for this question at starting only ->   **\" OpenAI tracks your usage of API models based on the number of tokens processed or requests made\"**\n",
    "- but i want a specific answer from retrieved document w.r.t question,,then use LLM for doing this task,,,,,,,,,,,where it will pass the returned document to LLM along with question,,,and llm will answer specifically,,,w/o giving thisbig document,,,,,,,,,,,\n",
    "- **so we go for RetrievalQA concept**,,,for increasing interactiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c126e6-c332-4587-8c07-b861f9b64434",
   "metadata": {},
   "source": [
    "### 4.3) RetrievalQA , for refining the response obtained from retriever object......."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60824b1-0219-484f-9513-bea5000d33c2",
   "metadata": {},
   "source": [
    "- **Basic RAG implementations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7d81a58-1ea4-45d7-90e4-ad20763beff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f758ece-464c-4e93-9b73-a7c5223fc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI() #U can use any model\n",
    "#from environmental variable it will access,,API key for openai\n",
    "#note-> we are not able to choose a specific model,,we get any of the default gpt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368856a4-0e50-401c-8bce-ca3b5659baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52e247-4bd3-4ce8-ad51-c75dabd18e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create chain to answer question\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever = retriever,\n",
    "    return_source_document = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccc76e-df5a-44eb-bdc9-e4b153aeb20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print(\"\\n\\nsources\")\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata[\"source\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5fa1e-b61e-4fd4-bd11-7aeb1e4c1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"charges for open AI model?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada50179-e456-44ac-bbac-8a158c847078",
   "metadata": {},
   "source": [
    "- **RetrievalQA Process**ie;qa_chain will pass question to retriever object and retriever object will give the most similar document to question and this answer and question is then passed to llm and get specific answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1020eb-b8eb-4044-bffc-5ba9c7144e12",
   "metadata": {},
   "source": [
    "- See, we have not getting response from LLM for our question, we are using llm for just refinement process..ie;to get specific data from received document (which is most similar to asked question)\n",
    "- you have 2 ways to do it,\n",
    " 1) finetune llm with above data(ie;your usecase data),,and directly ask question to that llm without using any vector db,,,\n",
    " 2) store your usecase data in database (sql , vector db(in the form of vectors/embeddings)),,and connect this database with your LLM,,,and ask question related to your data to LLM and it will answer it,,,,,,as we done above using RetrievalQA()..........and this 2nd way is known as **RAG(Retrieval Augmented Generation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92238758-4f6a-433f-82ce-6ca54825b219",
   "metadata": {},
   "source": [
    "- **We are getting Answers from vector db based on similarity b/n question vector (vector representation of question(text)) and answer vector,,,,,,,,,,\n",
    ",,,but vector db returns you complete document which is desired answer and also which is most similar with question vector.................as u see above,,when i asked \"how OpenAI tracks your usage of API?\",,,then it gives me most similar document to this question vector,,,,,,which contains answer,,,,but it also contains unneccssory text also,,,,and i want a specific answer from this document,,then we use llm to parse it.ie; we pass this document to our llm model and it will give you specific answer to our question**\n",
    "\n",
    "- and this process is called RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d292c1b-ae72-4739-aed9-711ee753744f",
   "metadata": {},
   "source": [
    "### Conclusion - LLM is just use for refining the answer from document we obtained from retriever....in RetrievalQA...which is RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd584bc1-f051-4511-8e30-e9c0cbe948e0",
   "metadata": {},
   "source": [
    "## 5) Delete my_chroma_db database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9f334-e7df-4e48-8071-7e67ff8a6a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mehthod 1\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()#to persist changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e5724-ec99-43d8-8c3b-a0eac4d92006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 2\n",
    "!zip -r my_chroma_db.zip ./my_chroma_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85704a-80e3-4383-b0e6-6315f169ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method 3\n",
    "!rm -rf my_chroma_db/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
